{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-07T15:18:45.350601Z",
     "iopub.status.busy": "2023-09-07T15:18:45.350373Z",
     "iopub.status.idle": "2023-09-07T15:18:45.869932Z",
     "shell.execute_reply": "2023-09-07T15:18:45.866864Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-07T15:18:45.875697Z",
     "iopub.status.busy": "2023-09-07T15:18:45.875013Z",
     "iopub.status.idle": "2023-09-07T15:18:54.429795Z",
     "shell.execute_reply": "2023-09-07T15:18:54.428801Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mi_quality</th>\n",
       "      <th>transcript_id</th>\n",
       "      <th>video_title</th>\n",
       "      <th>video_url</th>\n",
       "      <th>topic</th>\n",
       "      <th>utterance_id</th>\n",
       "      <th>interlocutor</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>utterance_text</th>\n",
       "      <th>annotator_id</th>\n",
       "      <th>...</th>\n",
       "      <th>reflection_exists</th>\n",
       "      <th>reflection_subtype</th>\n",
       "      <th>question_exists</th>\n",
       "      <th>question_subtype</th>\n",
       "      <th>main_therapist_behaviour</th>\n",
       "      <th>client_talk_type</th>\n",
       "      <th>client_audio_utterance</th>\n",
       "      <th>therapist_audio_utterance</th>\n",
       "      <th>client_hubert_emb</th>\n",
       "      <th>therapist_hubert_emb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>high</td>\n",
       "      <td>0</td>\n",
       "      <td>NEW VIDEO: Brief intervention: \"Barbara\"</td>\n",
       "      <td>https://www.youtube.com/watch?v=PaSKcfTmFEk</td>\n",
       "      <td>reducing alcohol consumption</td>\n",
       "      <td>0</td>\n",
       "      <td>therapist</td>\n",
       "      <td>00:00:13</td>\n",
       "      <td>thanks for filling it out we give this form to...</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>open</td>\n",
       "      <td>question</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>[0.002105713, 0.0020751953, 0.0026245117, 0.00...</td>\n",
       "      <td>None</td>\n",
       "      <td>[0.117147654, 0.3987467, 0.18795893, -0.138374...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>high</td>\n",
       "      <td>0</td>\n",
       "      <td>NEW VIDEO: Brief intervention: \"Barbara\"</td>\n",
       "      <td>https://www.youtube.com/watch?v=PaSKcfTmFEk</td>\n",
       "      <td>reducing alcohol consumption</td>\n",
       "      <td>1</td>\n",
       "      <td>client</td>\n",
       "      <td>00:00:24</td>\n",
       "      <td>sure</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[0.0057373047, 0.0033569336, 0.0014648438, -0....</td>\n",
       "      <td>None</td>\n",
       "      <td>[0.16314445, 0.33709005, 0.25657523, -0.106496...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>high</td>\n",
       "      <td>0</td>\n",
       "      <td>NEW VIDEO: Brief intervention: \"Barbara\"</td>\n",
       "      <td>https://www.youtube.com/watch?v=PaSKcfTmFEk</td>\n",
       "      <td>reducing alcohol consumption</td>\n",
       "      <td>2</td>\n",
       "      <td>therapist</td>\n",
       "      <td>00:00:25</td>\n",
       "      <td>so lets see it looks that you put you drink al...</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>therapist_input</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>[0.0008239746, 0.003479004, 0.0008544922, -0.0...</td>\n",
       "      <td>None</td>\n",
       "      <td>[0.1851178, 0.35557893, 0.19974922, -0.1263290...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>high</td>\n",
       "      <td>0</td>\n",
       "      <td>NEW VIDEO: Brief intervention: \"Barbara\"</td>\n",
       "      <td>https://www.youtube.com/watch?v=PaSKcfTmFEk</td>\n",
       "      <td>reducing alcohol consumption</td>\n",
       "      <td>3</td>\n",
       "      <td>client</td>\n",
       "      <td>00:00:34</td>\n",
       "      <td>mmhmm</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>[0.26716128, 0.33375242, 0.16871695, -0.183855...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>high</td>\n",
       "      <td>0</td>\n",
       "      <td>NEW VIDEO: Brief intervention: \"Barbara\"</td>\n",
       "      <td>https://www.youtube.com/watch?v=PaSKcfTmFEk</td>\n",
       "      <td>reducing alcohol consumption</td>\n",
       "      <td>4</td>\n",
       "      <td>therapist</td>\n",
       "      <td>00:00:34</td>\n",
       "      <td>and you usually have three to four drinks when...</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>therapist_input</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>[0.0077819824, 0.008422852, 0.009338379, 0.010...</td>\n",
       "      <td>None</td>\n",
       "      <td>[0.12812702, 0.33925486, 0.24788164, -0.148453...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  mi_quality  transcript_id                               video_title  \\\n",
       "0       high              0  NEW VIDEO: Brief intervention: \"Barbara\"   \n",
       "1       high              0  NEW VIDEO: Brief intervention: \"Barbara\"   \n",
       "2       high              0  NEW VIDEO: Brief intervention: \"Barbara\"   \n",
       "3       high              0  NEW VIDEO: Brief intervention: \"Barbara\"   \n",
       "4       high              0  NEW VIDEO: Brief intervention: \"Barbara\"   \n",
       "\n",
       "                                     video_url                         topic  \\\n",
       "0  https://www.youtube.com/watch?v=PaSKcfTmFEk  reducing alcohol consumption   \n",
       "1  https://www.youtube.com/watch?v=PaSKcfTmFEk  reducing alcohol consumption   \n",
       "2  https://www.youtube.com/watch?v=PaSKcfTmFEk  reducing alcohol consumption   \n",
       "3  https://www.youtube.com/watch?v=PaSKcfTmFEk  reducing alcohol consumption   \n",
       "4  https://www.youtube.com/watch?v=PaSKcfTmFEk  reducing alcohol consumption   \n",
       "\n",
       "   utterance_id interlocutor timestamp  \\\n",
       "0             0    therapist  00:00:13   \n",
       "1             1       client  00:00:24   \n",
       "2             2    therapist  00:00:25   \n",
       "3             3       client  00:00:34   \n",
       "4             4    therapist  00:00:34   \n",
       "\n",
       "                                      utterance_text  annotator_id  ...  \\\n",
       "0  thanks for filling it out we give this form to...             3  ...   \n",
       "1                                               sure             3  ...   \n",
       "2  so lets see it looks that you put you drink al...             3  ...   \n",
       "3                                              mmhmm             3  ...   \n",
       "4  and you usually have three to four drinks when...             3  ...   \n",
       "\n",
       "  reflection_exists reflection_subtype question_exists question_subtype  \\\n",
       "0             False                NaN            True             open   \n",
       "1               NaN                NaN             NaN              NaN   \n",
       "2             False                NaN           False              NaN   \n",
       "3               NaN                NaN             NaN              NaN   \n",
       "4             False                NaN           False              NaN   \n",
       "\n",
       "  main_therapist_behaviour client_talk_type  \\\n",
       "0                 question              NaN   \n",
       "1                      NaN          neutral   \n",
       "2          therapist_input              NaN   \n",
       "3                      NaN          neutral   \n",
       "4          therapist_input              NaN   \n",
       "\n",
       "                              client_audio_utterance  \\\n",
       "0                                               None   \n",
       "1  [0.0057373047, 0.0033569336, 0.0014648438, -0....   \n",
       "2                                               None   \n",
       "3                                                 []   \n",
       "4                                               None   \n",
       "\n",
       "                           therapist_audio_utterance  \\\n",
       "0  [0.002105713, 0.0020751953, 0.0026245117, 0.00...   \n",
       "1                                               None   \n",
       "2  [0.0008239746, 0.003479004, 0.0008544922, -0.0...   \n",
       "3                                               None   \n",
       "4  [0.0077819824, 0.008422852, 0.009338379, 0.010...   \n",
       "\n",
       "                                   client_hubert_emb  \\\n",
       "0                                               None   \n",
       "1  [0.16314445, 0.33709005, 0.25657523, -0.106496...   \n",
       "2                                               None   \n",
       "3  [0.26716128, 0.33375242, 0.16871695, -0.183855...   \n",
       "4                                               None   \n",
       "\n",
       "                                therapist_hubert_emb  \n",
       "0  [0.117147654, 0.3987467, 0.18795893, -0.138374...  \n",
       "1                                               None  \n",
       "2  [0.1851178, 0.35557893, 0.19974922, -0.1263290...  \n",
       "3                                               None  \n",
       "4  [0.12812702, 0.33925486, 0.24788164, -0.148453...  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('Annomi_HuBERT.pkl')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-07T15:18:54.474842Z",
     "iopub.status.busy": "2023-09-07T15:18:54.473095Z",
     "iopub.status.idle": "2023-09-07T15:18:54.483504Z",
     "shell.execute_reply": "2023-09-07T15:18:54.481818Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get a dataframe where interlocutor is cleint\n",
    "df_client = df[df['interlocutor'] == 'client']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-07T15:18:54.486973Z",
     "iopub.status.busy": "2023-09-07T15:18:54.486436Z",
     "iopub.status.idle": "2023-09-07T15:18:54.500714Z",
     "shell.execute_reply": "2023-09-07T15:18:54.499703Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mi_quality                      0\n",
       "transcript_id                   0\n",
       "video_title                     0\n",
       "video_url                       0\n",
       "topic                           0\n",
       "utterance_id                    0\n",
       "interlocutor                    0\n",
       "timestamp                       0\n",
       "utterance_text                  0\n",
       "annotator_id                    0\n",
       "therapist_input_exists       6338\n",
       "therapist_input_subtype      6338\n",
       "reflection_exists            6338\n",
       "reflection_subtype           6338\n",
       "question_exists              6338\n",
       "question_subtype             6338\n",
       "main_therapist_behaviour     6338\n",
       "client_talk_type                0\n",
       "client_audio_utterance          0\n",
       "therapist_audio_utterance    6338\n",
       "client_hubert_emb               0\n",
       "therapist_hubert_emb         6338\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_client.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-07T15:18:54.506729Z",
     "iopub.status.busy": "2023-09-07T15:18:54.506497Z",
     "iopub.status.idle": "2023-09-07T15:18:54.973238Z",
     "shell.execute_reply": "2023-09-07T15:18:54.972194Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-07T15:18:54.977833Z",
     "iopub.status.busy": "2023-09-07T15:18:54.977522Z",
     "iopub.status.idle": "2023-09-07T15:18:54.988880Z",
     "shell.execute_reply": "2023-09-07T15:18:54.987999Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split the df_therapist into train and test sets depending on the unique id of video_title\n",
    "# The train set contains 80% of the data and the test set contains 20% of the data\n",
    "\n",
    "video_titles = df_client['video_title'].unique()\n",
    "\n",
    "train_video_titles, test_video_titles = train_test_split(video_titles, test_size=0.2, random_state=42)\n",
    "\n",
    "train_df = df_client[df_client['video_title'].isin(train_video_titles)]\n",
    "test_df = df_client[df_client['video_title'].isin(test_video_titles)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-07T15:18:54.994088Z",
     "iopub.status.busy": "2023-09-07T15:18:54.993591Z",
     "iopub.status.idle": "2023-09-07T15:18:55.002807Z",
     "shell.execute_reply": "2023-09-07T15:18:55.001603Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original classes ['change' 'neutral' 'sustain']\n",
      "Corresponding numeric classes [0 1 2]\n"
     ]
    }
   ],
   "source": [
    "# labeling the y_train and y_test\n",
    "y_train_classes = train_df['client_talk_type']\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y_train_classes)\n",
    "print(f'Original classes {le.classes_}')\n",
    "print(f'Corresponding numeric classes {le.transform(le.classes_)}')\n",
    "y_train = le.transform(y_train_classes)\n",
    "y_test_classes = test_df['client_talk_type']\n",
    "y_test = le.transform(y_test_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-07T15:18:55.005651Z",
     "iopub.status.busy": "2023-09-07T15:18:55.005433Z",
     "iopub.status.idle": "2023-09-07T15:18:55.010311Z",
     "shell.execute_reply": "2023-09-07T15:18:55.009608Z"
    }
   },
   "outputs": [],
   "source": [
    "# X_train and X_test\n",
    "\n",
    "X_train = train_df['client_hubert_emb'].to_numpy()\n",
    "X_test = test_df['client_hubert_emb'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-07T15:18:55.018248Z",
     "iopub.status.busy": "2023-09-07T15:18:55.015571Z",
     "iopub.status.idle": "2023-09-07T15:18:59.783033Z",
     "shell.execute_reply": "2023-09-07T15:18:59.782172Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-07 15:18:57.472088: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-07 15:18:58.449890: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import f1_score\n",
    "from transformers import HubertModel\n",
    "from transformers import TrainingArguments, Trainer, AutoModel\n",
    "from transformers import TrainerCallback, IntervalStrategy\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-07T15:18:59.787725Z",
     "iopub.status.busy": "2023-09-07T15:18:59.786203Z",
     "iopub.status.idle": "2023-09-07T15:18:59.792231Z",
     "shell.execute_reply": "2023-09-07T15:18:59.791065Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-07T15:18:59.796053Z",
     "iopub.status.busy": "2023-09-07T15:18:59.795583Z",
     "iopub.status.idle": "2023-09-07T15:19:01.972728Z",
     "shell.execute_reply": "2023-09-07T15:19:01.971532Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert data to PyTorch tensors and move to device\n",
    "X_train_tensor = torch.stack([torch.Tensor(i) for i in X_train]).to(device)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long).to(device)\n",
    "\n",
    "X_test_tensor = torch.stack([torch.Tensor(i) for i in X_test]).to(device)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long).to(device)\n",
    "\n",
    "# Create DataLoader for training and testing data\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-07T15:19:01.977088Z",
     "iopub.status.busy": "2023-09-07T15:19:01.976621Z",
     "iopub.status.idle": "2023-09-07T15:19:01.995343Z",
     "shell.execute_reply": "2023-09-07T15:19:01.992214Z"
    }
   },
   "outputs": [],
   "source": [
    "class SimpleDNN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(SimpleDNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class ComplexModel(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(ComplexModel, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_size, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        self.fc4 = nn.Linear(256, 128)\n",
    "        self.fc5 = nn.Linear(128, num_classes)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.08)\n",
    "        self.batch_norm1 = nn.BatchNorm1d(1024)\n",
    "        self.batch_norm2 = nn.BatchNorm1d(512)\n",
    "        self.batch_norm3 = nn.BatchNorm1d(256)\n",
    "        self.batch_norm4 = nn.BatchNorm1d(128)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.batch_norm1(self.fc1(x)))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = F.relu(self.batch_norm2(self.fc2(x)))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = F.relu(self.batch_norm3(self.fc3(x)))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = F.relu(self.batch_norm4(self.fc4(x)))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.fc5(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, n_layers, dropout_prob):\n",
    "        super(LSTMModel, self).__init__()\n",
    "\n",
    "        # Define the LSTM layer\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, n_layers, dropout=dropout_prob, batch_first=True)\n",
    "\n",
    "        # Define a dropout layer\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "\n",
    "        # Define the final fully connected layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Assuming x is of shape (batch_size, sequence_length, input_dim)\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        \n",
    "        # Use dropout for regularization\n",
    "        out = self.dropout(lstm_out[:, -1, :])\n",
    "\n",
    "        # Pass through the fully connected layer\n",
    "        output = self.fc(out)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, reduce=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduce = reduce\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        CE_loss = nn.CrossEntropyLoss(reduction='none')(inputs, targets)\n",
    "        pt = torch.exp(-CE_loss)\n",
    "        F_loss = self.alpha * ((1-pt)**self.gamma) * CE_loss\n",
    "\n",
    "        if self.reduce:\n",
    "            return torch.mean(F_loss)\n",
    "        else:\n",
    "            return F_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-07T15:19:01.998879Z",
     "iopub.status.busy": "2023-09-07T15:19:01.998375Z",
     "iopub.status.idle": "2023-09-07T15:19:02.956717Z",
     "shell.execute_reply": "2023-09-07T15:19:02.953735Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create an instance of the model and move it to device\n",
    "num_classes = len(le.classes_)\n",
    "# model = SimpleDNN(input_size=X_train_tensor.size(1), num_classes=num_classes).to(device)\n",
    "model = LSTMModel(1024, 512, num_classes, 2, 0.1).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-07T15:19:02.962811Z",
     "iopub.status.busy": "2023-09-07T15:19:02.962270Z",
     "iopub.status.idle": "2023-09-08T07:48:34.459989Z",
     "shell.execute_reply": "2023-09-08T07:48:34.459001Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100000, Train Loss: 0.3954, Train F1: 0.2601, Validation Loss: 0.4216, Validation F1: 0.2367\n",
      "Epoch 200/100000, Train Loss: 0.3749, Train F1: 0.2601, Validation Loss: 0.4108, Validation F1: 0.2367\n",
      "Epoch 300/100000, Train Loss: 0.3736, Train F1: 0.2601, Validation Loss: 0.4073, Validation F1: 0.2367\n",
      "Epoch 400/100000, Train Loss: 0.3727, Train F1: 0.2601, Validation Loss: 0.4058, Validation F1: 0.2367\n",
      "Epoch 500/100000, Train Loss: 0.3720, Train F1: 0.2601, Validation Loss: 0.4049, Validation F1: 0.2367\n",
      "Epoch 600/100000, Train Loss: 0.3715, Train F1: 0.2601, Validation Loss: 0.4042, Validation F1: 0.2367\n",
      "Epoch 700/100000, Train Loss: 0.3715, Train F1: 0.2601, Validation Loss: 0.4037, Validation F1: 0.2367\n",
      "Epoch 800/100000, Train Loss: 0.3709, Train F1: 0.2601, Validation Loss: 0.4033, Validation F1: 0.2367\n",
      "Epoch 900/100000, Train Loss: 0.3708, Train F1: 0.2601, Validation Loss: 0.4029, Validation F1: 0.2367\n",
      "Epoch 1000/100000, Train Loss: 0.3701, Train F1: 0.2601, Validation Loss: 0.4026, Validation F1: 0.2367\n",
      "Epoch 1100/100000, Train Loss: 0.3697, Train F1: 0.2601, Validation Loss: 0.4023, Validation F1: 0.2367\n",
      "Epoch 1200/100000, Train Loss: 0.3693, Train F1: 0.2601, Validation Loss: 0.4021, Validation F1: 0.2367\n",
      "Epoch 1300/100000, Train Loss: 0.3688, Train F1: 0.2601, Validation Loss: 0.4019, Validation F1: 0.2367\n",
      "Epoch 1400/100000, Train Loss: 0.3687, Train F1: 0.2601, Validation Loss: 0.4017, Validation F1: 0.2367\n",
      "Epoch 1500/100000, Train Loss: 0.3682, Train F1: 0.2601, Validation Loss: 0.4015, Validation F1: 0.2367\n",
      "Epoch 1600/100000, Train Loss: 0.3683, Train F1: 0.2601, Validation Loss: 0.4014, Validation F1: 0.2367\n",
      "Epoch 1700/100000, Train Loss: 0.3679, Train F1: 0.2601, Validation Loss: 0.4013, Validation F1: 0.2367\n",
      "Epoch 1800/100000, Train Loss: 0.3678, Train F1: 0.2601, Validation Loss: 0.4012, Validation F1: 0.2367\n",
      "Epoch 1900/100000, Train Loss: 0.3673, Train F1: 0.2601, Validation Loss: 0.4011, Validation F1: 0.2367\n",
      "Epoch 2000/100000, Train Loss: 0.3670, Train F1: 0.2601, Validation Loss: 0.4010, Validation F1: 0.2367\n",
      "Epoch 2100/100000, Train Loss: 0.3668, Train F1: 0.2601, Validation Loss: 0.4010, Validation F1: 0.2367\n",
      "Epoch 2200/100000, Train Loss: 0.3665, Train F1: 0.2601, Validation Loss: 0.4009, Validation F1: 0.2367\n",
      "Epoch 2300/100000, Train Loss: 0.3665, Train F1: 0.2601, Validation Loss: 0.4009, Validation F1: 0.2367\n",
      "Epoch 2400/100000, Train Loss: 0.3662, Train F1: 0.2601, Validation Loss: 0.4009, Validation F1: 0.2367\n",
      "Epoch 2500/100000, Train Loss: 0.3655, Train F1: 0.2601, Validation Loss: 0.4009, Validation F1: 0.2367\n",
      "Epoch 2600/100000, Train Loss: 0.3657, Train F1: 0.2601, Validation Loss: 0.4009, Validation F1: 0.2367\n",
      "Epoch 2700/100000, Train Loss: 0.3652, Train F1: 0.2601, Validation Loss: 0.4010, Validation F1: 0.2367\n",
      "Epoch 2800/100000, Train Loss: 0.3651, Train F1: 0.2601, Validation Loss: 0.4010, Validation F1: 0.2367\n",
      "Epoch 2900/100000, Train Loss: 0.3647, Train F1: 0.2601, Validation Loss: 0.4011, Validation F1: 0.2367\n",
      "Epoch 3000/100000, Train Loss: 0.3642, Train F1: 0.2601, Validation Loss: 0.4011, Validation F1: 0.2367\n",
      "Epoch 3100/100000, Train Loss: 0.3644, Train F1: 0.2601, Validation Loss: 0.4013, Validation F1: 0.2367\n",
      "Epoch 3200/100000, Train Loss: 0.3641, Train F1: 0.2601, Validation Loss: 0.4013, Validation F1: 0.2367\n",
      "Epoch 3300/100000, Train Loss: 0.3636, Train F1: 0.2601, Validation Loss: 0.4015, Validation F1: 0.2367\n",
      "Epoch 3400/100000, Train Loss: 0.3636, Train F1: 0.2601, Validation Loss: 0.4016, Validation F1: 0.2367\n",
      "Epoch 3500/100000, Train Loss: 0.3633, Train F1: 0.2601, Validation Loss: 0.4017, Validation F1: 0.2367\n",
      "Epoch 3600/100000, Train Loss: 0.3630, Train F1: 0.2601, Validation Loss: 0.4018, Validation F1: 0.2367\n",
      "Epoch 3700/100000, Train Loss: 0.3631, Train F1: 0.2601, Validation Loss: 0.4019, Validation F1: 0.2367\n",
      "Epoch 3800/100000, Train Loss: 0.3625, Train F1: 0.2601, Validation Loss: 0.4020, Validation F1: 0.2367\n",
      "Epoch 3900/100000, Train Loss: 0.3626, Train F1: 0.2601, Validation Loss: 0.4022, Validation F1: 0.2367\n",
      "Epoch 4000/100000, Train Loss: 0.3620, Train F1: 0.2602, Validation Loss: 0.4023, Validation F1: 0.2367\n",
      "Epoch 4100/100000, Train Loss: 0.3621, Train F1: 0.2602, Validation Loss: 0.4025, Validation F1: 0.2367\n",
      "Epoch 4200/100000, Train Loss: 0.3618, Train F1: 0.2601, Validation Loss: 0.4026, Validation F1: 0.2367\n",
      "Epoch 4300/100000, Train Loss: 0.3619, Train F1: 0.2601, Validation Loss: 0.4028, Validation F1: 0.2367\n",
      "Epoch 4400/100000, Train Loss: 0.3612, Train F1: 0.2607, Validation Loss: 0.4029, Validation F1: 0.2367\n",
      "Epoch 4500/100000, Train Loss: 0.3613, Train F1: 0.2607, Validation Loss: 0.4031, Validation F1: 0.2367\n",
      "Epoch 4600/100000, Train Loss: 0.3611, Train F1: 0.2607, Validation Loss: 0.4033, Validation F1: 0.2367\n",
      "Epoch 4700/100000, Train Loss: 0.3608, Train F1: 0.2601, Validation Loss: 0.4034, Validation F1: 0.2367\n",
      "Epoch 4800/100000, Train Loss: 0.3605, Train F1: 0.2607, Validation Loss: 0.4036, Validation F1: 0.2367\n",
      "Epoch 4900/100000, Train Loss: 0.3603, Train F1: 0.2601, Validation Loss: 0.4037, Validation F1: 0.2367\n",
      "Epoch 5000/100000, Train Loss: 0.3602, Train F1: 0.2601, Validation Loss: 0.4039, Validation F1: 0.2367\n",
      "Epoch 5100/100000, Train Loss: 0.3601, Train F1: 0.2607, Validation Loss: 0.4040, Validation F1: 0.2367\n",
      "Epoch 5200/100000, Train Loss: 0.3594, Train F1: 0.2613, Validation Loss: 0.4042, Validation F1: 0.2367\n",
      "Epoch 5300/100000, Train Loss: 0.3594, Train F1: 0.2613, Validation Loss: 0.4043, Validation F1: 0.2367\n",
      "Epoch 5400/100000, Train Loss: 0.3596, Train F1: 0.2624, Validation Loss: 0.4045, Validation F1: 0.2367\n",
      "Epoch 5500/100000, Train Loss: 0.3593, Train F1: 0.2618, Validation Loss: 0.4046, Validation F1: 0.2367\n",
      "Epoch 5600/100000, Train Loss: 0.3591, Train F1: 0.2630, Validation Loss: 0.4048, Validation F1: 0.2385\n",
      "Epoch 5700/100000, Train Loss: 0.3587, Train F1: 0.2640, Validation Loss: 0.4050, Validation F1: 0.2385\n",
      "Epoch 5800/100000, Train Loss: 0.3583, Train F1: 0.2645, Validation Loss: 0.4051, Validation F1: 0.2406\n",
      "Epoch 5900/100000, Train Loss: 0.3581, Train F1: 0.2640, Validation Loss: 0.4052, Validation F1: 0.2426\n",
      "Epoch 6000/100000, Train Loss: 0.3584, Train F1: 0.2650, Validation Loss: 0.4054, Validation F1: 0.2426\n",
      "Epoch 6100/100000, Train Loss: 0.3580, Train F1: 0.2676, Validation Loss: 0.4056, Validation F1: 0.2441\n",
      "Epoch 6200/100000, Train Loss: 0.3577, Train F1: 0.2660, Validation Loss: 0.4057, Validation F1: 0.2438\n",
      "Epoch 6300/100000, Train Loss: 0.3574, Train F1: 0.2710, Validation Loss: 0.4058, Validation F1: 0.2435\n",
      "Epoch 6400/100000, Train Loss: 0.3572, Train F1: 0.2718, Validation Loss: 0.4060, Validation F1: 0.2456\n",
      "Epoch 6500/100000, Train Loss: 0.3571, Train F1: 0.2713, Validation Loss: 0.4062, Validation F1: 0.2473\n",
      "Epoch 6600/100000, Train Loss: 0.3569, Train F1: 0.2721, Validation Loss: 0.4063, Validation F1: 0.2470\n",
      "Epoch 6700/100000, Train Loss: 0.3567, Train F1: 0.2740, Validation Loss: 0.4064, Validation F1: 0.2468\n",
      "Epoch 6800/100000, Train Loss: 0.3564, Train F1: 0.2817, Validation Loss: 0.4066, Validation F1: 0.2465\n",
      "Epoch 6900/100000, Train Loss: 0.3564, Train F1: 0.2803, Validation Loss: 0.4067, Validation F1: 0.2501\n",
      "Epoch 7000/100000, Train Loss: 0.3561, Train F1: 0.2844, Validation Loss: 0.4068, Validation F1: 0.2521\n",
      "Epoch 7100/100000, Train Loss: 0.3562, Train F1: 0.2789, Validation Loss: 0.4070, Validation F1: 0.2540\n",
      "Epoch 7200/100000, Train Loss: 0.3555, Train F1: 0.2842, Validation Loss: 0.4071, Validation F1: 0.2635\n",
      "Epoch 7300/100000, Train Loss: 0.3555, Train F1: 0.2891, Validation Loss: 0.4072, Validation F1: 0.2647\n",
      "Epoch 7400/100000, Train Loss: 0.3554, Train F1: 0.2861, Validation Loss: 0.4074, Validation F1: 0.2647\n",
      "Epoch 7500/100000, Train Loss: 0.3553, Train F1: 0.2893, Validation Loss: 0.4075, Validation F1: 0.2674\n",
      "Epoch 7600/100000, Train Loss: 0.3549, Train F1: 0.2904, Validation Loss: 0.4076, Validation F1: 0.2689\n",
      "Epoch 7700/100000, Train Loss: 0.3551, Train F1: 0.2962, Validation Loss: 0.4077, Validation F1: 0.2697\n",
      "Epoch 7800/100000, Train Loss: 0.3546, Train F1: 0.2955, Validation Loss: 0.4078, Validation F1: 0.2714\n",
      "Epoch 7900/100000, Train Loss: 0.3540, Train F1: 0.2989, Validation Loss: 0.4079, Validation F1: 0.2714\n",
      "Epoch 8000/100000, Train Loss: 0.3541, Train F1: 0.2994, Validation Loss: 0.4080, Validation F1: 0.2711\n",
      "Epoch 8100/100000, Train Loss: 0.3543, Train F1: 0.3011, Validation Loss: 0.4081, Validation F1: 0.2704\n",
      "Epoch 8200/100000, Train Loss: 0.3535, Train F1: 0.3046, Validation Loss: 0.4082, Validation F1: 0.2697\n",
      "Epoch 8300/100000, Train Loss: 0.3536, Train F1: 0.3055, Validation Loss: 0.4083, Validation F1: 0.2690\n",
      "Epoch 8400/100000, Train Loss: 0.3537, Train F1: 0.3092, Validation Loss: 0.4084, Validation F1: 0.2709\n",
      "Epoch 8500/100000, Train Loss: 0.3533, Train F1: 0.3068, Validation Loss: 0.4085, Validation F1: 0.2726\n",
      "Epoch 8600/100000, Train Loss: 0.3535, Train F1: 0.3061, Validation Loss: 0.4085, Validation F1: 0.2736\n",
      "Epoch 8700/100000, Train Loss: 0.3530, Train F1: 0.3140, Validation Loss: 0.4086, Validation F1: 0.2770\n",
      "Epoch 8800/100000, Train Loss: 0.3524, Train F1: 0.3122, Validation Loss: 0.4087, Validation F1: 0.2763\n",
      "Epoch 8900/100000, Train Loss: 0.3528, Train F1: 0.3118, Validation Loss: 0.4088, Validation F1: 0.2776\n",
      "Epoch 9000/100000, Train Loss: 0.3522, Train F1: 0.3119, Validation Loss: 0.4089, Validation F1: 0.2793\n",
      "Epoch 9100/100000, Train Loss: 0.3525, Train F1: 0.3182, Validation Loss: 0.4089, Validation F1: 0.2789\n",
      "Epoch 9200/100000, Train Loss: 0.3517, Train F1: 0.3164, Validation Loss: 0.4090, Validation F1: 0.2814\n",
      "Epoch 9300/100000, Train Loss: 0.3516, Train F1: 0.3171, Validation Loss: 0.4091, Validation F1: 0.2810\n",
      "Epoch 9400/100000, Train Loss: 0.3516, Train F1: 0.3215, Validation Loss: 0.4091, Validation F1: 0.2835\n",
      "Epoch 9500/100000, Train Loss: 0.3511, Train F1: 0.3272, Validation Loss: 0.4092, Validation F1: 0.2831\n",
      "Epoch 9600/100000, Train Loss: 0.3506, Train F1: 0.3259, Validation Loss: 0.4093, Validation F1: 0.2831\n",
      "Epoch 9700/100000, Train Loss: 0.3510, Train F1: 0.3261, Validation Loss: 0.4093, Validation F1: 0.2847\n",
      "Epoch 9800/100000, Train Loss: 0.3505, Train F1: 0.3251, Validation Loss: 0.4094, Validation F1: 0.2864\n",
      "Epoch 9900/100000, Train Loss: 0.3505, Train F1: 0.3328, Validation Loss: 0.4095, Validation F1: 0.2864\n",
      "Epoch 10000/100000, Train Loss: 0.3500, Train F1: 0.3296, Validation Loss: 0.4095, Validation F1: 0.2887\n",
      "Epoch 10100/100000, Train Loss: 0.3496, Train F1: 0.3295, Validation Loss: 0.4095, Validation F1: 0.2899\n",
      "Epoch 10200/100000, Train Loss: 0.3502, Train F1: 0.3315, Validation Loss: 0.4096, Validation F1: 0.2899\n",
      "Epoch 10300/100000, Train Loss: 0.3493, Train F1: 0.3305, Validation Loss: 0.4097, Validation F1: 0.2899\n",
      "Epoch 10400/100000, Train Loss: 0.3492, Train F1: 0.3360, Validation Loss: 0.4097, Validation F1: 0.2910\n",
      "Epoch 10500/100000, Train Loss: 0.3489, Train F1: 0.3344, Validation Loss: 0.4098, Validation F1: 0.2926\n",
      "Epoch 10600/100000, Train Loss: 0.3488, Train F1: 0.3384, Validation Loss: 0.4099, Validation F1: 0.2926\n",
      "Epoch 10700/100000, Train Loss: 0.3490, Train F1: 0.3381, Validation Loss: 0.4099, Validation F1: 0.2941\n",
      "Epoch 10800/100000, Train Loss: 0.3486, Train F1: 0.3407, Validation Loss: 0.4100, Validation F1: 0.2952\n",
      "Epoch 10900/100000, Train Loss: 0.3484, Train F1: 0.3395, Validation Loss: 0.4100, Validation F1: 0.2948\n",
      "Epoch 11000/100000, Train Loss: 0.3482, Train F1: 0.3383, Validation Loss: 0.4101, Validation F1: 0.2940\n",
      "Epoch 11100/100000, Train Loss: 0.3474, Train F1: 0.3423, Validation Loss: 0.4101, Validation F1: 0.2940\n",
      "Epoch 11200/100000, Train Loss: 0.3473, Train F1: 0.3458, Validation Loss: 0.4101, Validation F1: 0.2936\n",
      "Epoch 11300/100000, Train Loss: 0.3468, Train F1: 0.3442, Validation Loss: 0.4102, Validation F1: 0.2951\n",
      "Epoch 11400/100000, Train Loss: 0.3478, Train F1: 0.3412, Validation Loss: 0.4103, Validation F1: 0.2951\n",
      "Epoch 11500/100000, Train Loss: 0.3464, Train F1: 0.3444, Validation Loss: 0.4104, Validation F1: 0.2951\n",
      "Epoch 11600/100000, Train Loss: 0.3464, Train F1: 0.3454, Validation Loss: 0.4104, Validation F1: 0.2951\n",
      "Epoch 11700/100000, Train Loss: 0.3467, Train F1: 0.3448, Validation Loss: 0.4105, Validation F1: 0.2947\n",
      "Epoch 11800/100000, Train Loss: 0.3455, Train F1: 0.3498, Validation Loss: 0.4105, Validation F1: 0.2962\n",
      "Epoch 11900/100000, Train Loss: 0.3456, Train F1: 0.3470, Validation Loss: 0.4106, Validation F1: 0.2991\n",
      "Epoch 12000/100000, Train Loss: 0.3453, Train F1: 0.3474, Validation Loss: 0.4106, Validation F1: 0.3002\n",
      "Epoch 12100/100000, Train Loss: 0.3455, Train F1: 0.3531, Validation Loss: 0.4107, Validation F1: 0.3002\n",
      "Epoch 12200/100000, Train Loss: 0.3450, Train F1: 0.3476, Validation Loss: 0.4107, Validation F1: 0.3012\n",
      "Epoch 12300/100000, Train Loss: 0.3444, Train F1: 0.3496, Validation Loss: 0.4108, Validation F1: 0.3008\n",
      "Epoch 12400/100000, Train Loss: 0.3443, Train F1: 0.3556, Validation Loss: 0.4109, Validation F1: 0.3004\n",
      "Epoch 12500/100000, Train Loss: 0.3443, Train F1: 0.3514, Validation Loss: 0.4109, Validation F1: 0.3004\n",
      "Epoch 12600/100000, Train Loss: 0.3440, Train F1: 0.3540, Validation Loss: 0.4110, Validation F1: 0.3004\n",
      "Epoch 12700/100000, Train Loss: 0.3446, Train F1: 0.3539, Validation Loss: 0.4110, Validation F1: 0.3004\n",
      "Epoch 12800/100000, Train Loss: 0.3437, Train F1: 0.3565, Validation Loss: 0.4111, Validation F1: 0.3004\n",
      "Epoch 12900/100000, Train Loss: 0.3435, Train F1: 0.3613, Validation Loss: 0.4110, Validation F1: 0.3014\n",
      "Epoch 13000/100000, Train Loss: 0.3436, Train F1: 0.3569, Validation Loss: 0.4111, Validation F1: 0.3029\n",
      "Epoch 13100/100000, Train Loss: 0.3426, Train F1: 0.3623, Validation Loss: 0.4112, Validation F1: 0.3029\n",
      "Epoch 13200/100000, Train Loss: 0.3430, Train F1: 0.3629, Validation Loss: 0.4113, Validation F1: 0.3072\n",
      "Epoch 13300/100000, Train Loss: 0.3430, Train F1: 0.3620, Validation Loss: 0.4114, Validation F1: 0.3070\n",
      "Epoch 13400/100000, Train Loss: 0.3423, Train F1: 0.3659, Validation Loss: 0.4114, Validation F1: 0.3086\n",
      "Epoch 13500/100000, Train Loss: 0.3417, Train F1: 0.3614, Validation Loss: 0.4114, Validation F1: 0.3086\n",
      "Epoch 13600/100000, Train Loss: 0.3411, Train F1: 0.3627, Validation Loss: 0.4114, Validation F1: 0.3082\n",
      "Epoch 13700/100000, Train Loss: 0.3410, Train F1: 0.3727, Validation Loss: 0.4114, Validation F1: 0.3077\n",
      "Epoch 13800/100000, Train Loss: 0.3407, Train F1: 0.3753, Validation Loss: 0.4115, Validation F1: 0.3106\n",
      "Epoch 13900/100000, Train Loss: 0.3411, Train F1: 0.3671, Validation Loss: 0.4116, Validation F1: 0.3093\n",
      "Epoch 14000/100000, Train Loss: 0.3403, Train F1: 0.3699, Validation Loss: 0.4117, Validation F1: 0.3107\n",
      "Epoch 14100/100000, Train Loss: 0.3402, Train F1: 0.3706, Validation Loss: 0.4117, Validation F1: 0.3104\n",
      "Epoch 14200/100000, Train Loss: 0.3399, Train F1: 0.3680, Validation Loss: 0.4118, Validation F1: 0.3093\n",
      "Epoch 14300/100000, Train Loss: 0.3398, Train F1: 0.3723, Validation Loss: 0.4119, Validation F1: 0.3093\n",
      "Epoch 14400/100000, Train Loss: 0.3397, Train F1: 0.3779, Validation Loss: 0.4119, Validation F1: 0.3092\n",
      "Epoch 14500/100000, Train Loss: 0.3401, Train F1: 0.3737, Validation Loss: 0.4120, Validation F1: 0.3088\n",
      "Epoch 14600/100000, Train Loss: 0.3395, Train F1: 0.3812, Validation Loss: 0.4121, Validation F1: 0.3088\n",
      "Epoch 14700/100000, Train Loss: 0.3391, Train F1: 0.3771, Validation Loss: 0.4121, Validation F1: 0.3116\n",
      "Epoch 14800/100000, Train Loss: 0.3391, Train F1: 0.3747, Validation Loss: 0.4120, Validation F1: 0.3130\n",
      "Epoch 14900/100000, Train Loss: 0.3384, Train F1: 0.3829, Validation Loss: 0.4120, Validation F1: 0.3131\n",
      "Epoch 15000/100000, Train Loss: 0.3385, Train F1: 0.3777, Validation Loss: 0.4122, Validation F1: 0.3131\n",
      "Epoch 15100/100000, Train Loss: 0.3387, Train F1: 0.3801, Validation Loss: 0.4122, Validation F1: 0.3226\n",
      "Epoch 15200/100000, Train Loss: 0.3383, Train F1: 0.3841, Validation Loss: 0.4123, Validation F1: 0.3221\n",
      "Epoch 15300/100000, Train Loss: 0.3384, Train F1: 0.3824, Validation Loss: 0.4123, Validation F1: 0.3235\n",
      "Epoch 15400/100000, Train Loss: 0.3373, Train F1: 0.3891, Validation Loss: 0.4124, Validation F1: 0.3236\n",
      "Epoch 15500/100000, Train Loss: 0.3385, Train F1: 0.3808, Validation Loss: 0.4123, Validation F1: 0.3227\n",
      "Epoch 15600/100000, Train Loss: 0.3368, Train F1: 0.3875, Validation Loss: 0.4123, Validation F1: 0.3227\n",
      "Epoch 15700/100000, Train Loss: 0.3377, Train F1: 0.3870, Validation Loss: 0.4124, Validation F1: 0.3228\n",
      "Epoch 15800/100000, Train Loss: 0.3360, Train F1: 0.3878, Validation Loss: 0.4124, Validation F1: 0.3242\n",
      "Epoch 15900/100000, Train Loss: 0.3369, Train F1: 0.3858, Validation Loss: 0.4125, Validation F1: 0.3243\n",
      "Epoch 16000/100000, Train Loss: 0.3364, Train F1: 0.3954, Validation Loss: 0.4126, Validation F1: 0.3286\n",
      "Epoch 16100/100000, Train Loss: 0.3365, Train F1: 0.3919, Validation Loss: 0.4125, Validation F1: 0.3284\n",
      "Epoch 16200/100000, Train Loss: 0.3353, Train F1: 0.3997, Validation Loss: 0.4127, Validation F1: 0.3285\n",
      "Epoch 16300/100000, Train Loss: 0.3355, Train F1: 0.3958, Validation Loss: 0.4126, Validation F1: 0.3286\n",
      "Epoch 16400/100000, Train Loss: 0.3353, Train F1: 0.3885, Validation Loss: 0.4127, Validation F1: 0.3286\n",
      "Epoch 16500/100000, Train Loss: 0.3348, Train F1: 0.3975, Validation Loss: 0.4127, Validation F1: 0.3321\n",
      "Epoch 16600/100000, Train Loss: 0.3355, Train F1: 0.3981, Validation Loss: 0.4127, Validation F1: 0.3321\n",
      "Epoch 16700/100000, Train Loss: 0.3355, Train F1: 0.3954, Validation Loss: 0.4128, Validation F1: 0.3327\n",
      "Epoch 16800/100000, Train Loss: 0.3353, Train F1: 0.4016, Validation Loss: 0.4128, Validation F1: 0.3323\n",
      "Epoch 16900/100000, Train Loss: 0.3350, Train F1: 0.4042, Validation Loss: 0.4128, Validation F1: 0.3336\n",
      "Epoch 17000/100000, Train Loss: 0.3344, Train F1: 0.4034, Validation Loss: 0.4129, Validation F1: 0.3336\n",
      "Epoch 17100/100000, Train Loss: 0.3338, Train F1: 0.4079, Validation Loss: 0.4129, Validation F1: 0.3333\n",
      "Epoch 17200/100000, Train Loss: 0.3332, Train F1: 0.4083, Validation Loss: 0.4129, Validation F1: 0.3346\n",
      "Epoch 17300/100000, Train Loss: 0.3341, Train F1: 0.4076, Validation Loss: 0.4130, Validation F1: 0.3342\n",
      "Epoch 17400/100000, Train Loss: 0.3337, Train F1: 0.4035, Validation Loss: 0.4130, Validation F1: 0.3369\n",
      "Epoch 17500/100000, Train Loss: 0.3333, Train F1: 0.4102, Validation Loss: 0.4131, Validation F1: 0.3369\n",
      "Epoch 17600/100000, Train Loss: 0.3321, Train F1: 0.4102, Validation Loss: 0.4130, Validation F1: 0.3382\n",
      "Epoch 17700/100000, Train Loss: 0.3334, Train F1: 0.4098, Validation Loss: 0.4132, Validation F1: 0.3382\n",
      "Epoch 17800/100000, Train Loss: 0.3322, Train F1: 0.4106, Validation Loss: 0.4131, Validation F1: 0.3410\n",
      "Epoch 17900/100000, Train Loss: 0.3320, Train F1: 0.4118, Validation Loss: 0.4132, Validation F1: 0.3410\n",
      "Epoch 18000/100000, Train Loss: 0.3322, Train F1: 0.4070, Validation Loss: 0.4132, Validation F1: 0.3419\n",
      "Epoch 18100/100000, Train Loss: 0.3313, Train F1: 0.4151, Validation Loss: 0.4133, Validation F1: 0.3416\n",
      "Epoch 18200/100000, Train Loss: 0.3314, Train F1: 0.4152, Validation Loss: 0.4133, Validation F1: 0.3416\n",
      "Epoch 18300/100000, Train Loss: 0.3317, Train F1: 0.4071, Validation Loss: 0.4133, Validation F1: 0.3416\n",
      "Epoch 18400/100000, Train Loss: 0.3328, Train F1: 0.4079, Validation Loss: 0.4133, Validation F1: 0.3471\n",
      "Epoch 18500/100000, Train Loss: 0.3319, Train F1: 0.4153, Validation Loss: 0.4133, Validation F1: 0.3510\n",
      "Epoch 18600/100000, Train Loss: 0.3316, Train F1: 0.4186, Validation Loss: 0.4133, Validation F1: 0.3493\n",
      "Epoch 18700/100000, Train Loss: 0.3310, Train F1: 0.4202, Validation Loss: 0.4133, Validation F1: 0.3493\n",
      "Epoch 18800/100000, Train Loss: 0.3312, Train F1: 0.4161, Validation Loss: 0.4133, Validation F1: 0.3488\n",
      "Epoch 18900/100000, Train Loss: 0.3309, Train F1: 0.4236, Validation Loss: 0.4134, Validation F1: 0.3493\n",
      "Epoch 19000/100000, Train Loss: 0.3310, Train F1: 0.4195, Validation Loss: 0.4135, Validation F1: 0.3493\n",
      "Epoch 19100/100000, Train Loss: 0.3304, Train F1: 0.4266, Validation Loss: 0.4133, Validation F1: 0.3488\n",
      "Epoch 19200/100000, Train Loss: 0.3300, Train F1: 0.4264, Validation Loss: 0.4134, Validation F1: 0.3562\n",
      "Epoch 19300/100000, Train Loss: 0.3309, Train F1: 0.4297, Validation Loss: 0.4135, Validation F1: 0.3567\n",
      "Epoch 19400/100000, Train Loss: 0.3296, Train F1: 0.4258, Validation Loss: 0.4135, Validation F1: 0.3576\n",
      "Epoch 19500/100000, Train Loss: 0.3296, Train F1: 0.4292, Validation Loss: 0.4136, Validation F1: 0.3581\n",
      "Epoch 19600/100000, Train Loss: 0.3288, Train F1: 0.4254, Validation Loss: 0.4135, Validation F1: 0.3566\n",
      "Epoch 19700/100000, Train Loss: 0.3292, Train F1: 0.4265, Validation Loss: 0.4135, Validation F1: 0.3566\n",
      "Epoch 19800/100000, Train Loss: 0.3290, Train F1: 0.4307, Validation Loss: 0.4137, Validation F1: 0.3571\n",
      "Epoch 19900/100000, Train Loss: 0.3285, Train F1: 0.4295, Validation Loss: 0.4136, Validation F1: 0.3598\n",
      "Epoch 20000/100000, Train Loss: 0.3291, Train F1: 0.4286, Validation Loss: 0.4136, Validation F1: 0.3611\n",
      "Epoch 20100/100000, Train Loss: 0.3288, Train F1: 0.4324, Validation Loss: 0.4137, Validation F1: 0.3620\n",
      "Epoch 20200/100000, Train Loss: 0.3298, Train F1: 0.4303, Validation Loss: 0.4137, Validation F1: 0.3615\n",
      "Epoch 20300/100000, Train Loss: 0.3278, Train F1: 0.4344, Validation Loss: 0.4137, Validation F1: 0.3611\n",
      "Epoch 20400/100000, Train Loss: 0.3291, Train F1: 0.4275, Validation Loss: 0.4139, Validation F1: 0.3616\n",
      "Epoch 20500/100000, Train Loss: 0.3285, Train F1: 0.4280, Validation Loss: 0.4138, Validation F1: 0.3616\n",
      "Epoch 20600/100000, Train Loss: 0.3284, Train F1: 0.4316, Validation Loss: 0.4138, Validation F1: 0.3602\n",
      "Epoch 20700/100000, Train Loss: 0.3276, Train F1: 0.4338, Validation Loss: 0.4137, Validation F1: 0.3588\n",
      "Epoch 20800/100000, Train Loss: 0.3278, Train F1: 0.4361, Validation Loss: 0.4138, Validation F1: 0.3587\n",
      "Epoch 20900/100000, Train Loss: 0.3269, Train F1: 0.4384, Validation Loss: 0.4140, Validation F1: 0.3603\n",
      "Epoch 21000/100000, Train Loss: 0.3275, Train F1: 0.4405, Validation Loss: 0.4140, Validation F1: 0.3592\n",
      "Epoch 21100/100000, Train Loss: 0.3271, Train F1: 0.4356, Validation Loss: 0.4140, Validation F1: 0.3628\n",
      "Epoch 21200/100000, Train Loss: 0.3271, Train F1: 0.4370, Validation Loss: 0.4139, Validation F1: 0.3639\n",
      "Epoch 21300/100000, Train Loss: 0.3276, Train F1: 0.4332, Validation Loss: 0.4140, Validation F1: 0.3653\n",
      "Epoch 21400/100000, Train Loss: 0.3267, Train F1: 0.4404, Validation Loss: 0.4140, Validation F1: 0.3653\n",
      "Epoch 21500/100000, Train Loss: 0.3270, Train F1: 0.4379, Validation Loss: 0.4141, Validation F1: 0.3640\n",
      "Epoch 21600/100000, Train Loss: 0.3274, Train F1: 0.4352, Validation Loss: 0.4143, Validation F1: 0.3640\n",
      "Epoch 21700/100000, Train Loss: 0.3263, Train F1: 0.4314, Validation Loss: 0.4141, Validation F1: 0.3643\n",
      "Epoch 21800/100000, Train Loss: 0.3266, Train F1: 0.4391, Validation Loss: 0.4141, Validation F1: 0.3643\n",
      "Epoch 21900/100000, Train Loss: 0.3266, Train F1: 0.4434, Validation Loss: 0.4142, Validation F1: 0.3635\n",
      "Epoch 22000/100000, Train Loss: 0.3267, Train F1: 0.4330, Validation Loss: 0.4143, Validation F1: 0.3634\n",
      "Epoch 22100/100000, Train Loss: 0.3264, Train F1: 0.4404, Validation Loss: 0.4143, Validation F1: 0.3648\n",
      "Epoch 22200/100000, Train Loss: 0.3263, Train F1: 0.4390, Validation Loss: 0.4143, Validation F1: 0.3716\n",
      "Epoch 22300/100000, Train Loss: 0.3248, Train F1: 0.4429, Validation Loss: 0.4144, Validation F1: 0.3702\n",
      "Epoch 22400/100000, Train Loss: 0.3258, Train F1: 0.4439, Validation Loss: 0.4143, Validation F1: 0.3716\n",
      "Epoch 22500/100000, Train Loss: 0.3242, Train F1: 0.4458, Validation Loss: 0.4145, Validation F1: 0.3702\n",
      "Epoch 22600/100000, Train Loss: 0.3247, Train F1: 0.4503, Validation Loss: 0.4144, Validation F1: 0.3716\n",
      "Epoch 22700/100000, Train Loss: 0.3255, Train F1: 0.4506, Validation Loss: 0.4145, Validation F1: 0.3715\n",
      "Epoch 22800/100000, Train Loss: 0.3241, Train F1: 0.4470, Validation Loss: 0.4144, Validation F1: 0.3715\n",
      "Epoch 22900/100000, Train Loss: 0.3240, Train F1: 0.4480, Validation Loss: 0.4146, Validation F1: 0.3728\n",
      "Epoch 23000/100000, Train Loss: 0.3248, Train F1: 0.4455, Validation Loss: 0.4145, Validation F1: 0.3728\n",
      "Epoch 23100/100000, Train Loss: 0.3236, Train F1: 0.4497, Validation Loss: 0.4147, Validation F1: 0.3728\n",
      "Epoch 23200/100000, Train Loss: 0.3243, Train F1: 0.4429, Validation Loss: 0.4145, Validation F1: 0.3728\n",
      "Epoch 23300/100000, Train Loss: 0.3238, Train F1: 0.4518, Validation Loss: 0.4147, Validation F1: 0.3728\n",
      "Epoch 23400/100000, Train Loss: 0.3239, Train F1: 0.4438, Validation Loss: 0.4146, Validation F1: 0.3741\n",
      "Epoch 23500/100000, Train Loss: 0.3239, Train F1: 0.4526, Validation Loss: 0.4147, Validation F1: 0.3741\n",
      "Epoch 23600/100000, Train Loss: 0.3237, Train F1: 0.4453, Validation Loss: 0.4148, Validation F1: 0.3741\n",
      "Epoch 23700/100000, Train Loss: 0.3230, Train F1: 0.4565, Validation Loss: 0.4148, Validation F1: 0.3741\n",
      "Epoch 23800/100000, Train Loss: 0.3236, Train F1: 0.4517, Validation Loss: 0.4148, Validation F1: 0.3741\n",
      "Epoch 23900/100000, Train Loss: 0.3238, Train F1: 0.4472, Validation Loss: 0.4147, Validation F1: 0.3741\n",
      "Epoch 24000/100000, Train Loss: 0.3220, Train F1: 0.4543, Validation Loss: 0.4148, Validation F1: 0.3741\n",
      "Epoch 24100/100000, Train Loss: 0.3240, Train F1: 0.4489, Validation Loss: 0.4148, Validation F1: 0.3746\n",
      "Epoch 24200/100000, Train Loss: 0.3225, Train F1: 0.4519, Validation Loss: 0.4148, Validation F1: 0.3778\n",
      "Epoch 24300/100000, Train Loss: 0.3232, Train F1: 0.4502, Validation Loss: 0.4149, Validation F1: 0.3782\n",
      "Epoch 24400/100000, Train Loss: 0.3224, Train F1: 0.4586, Validation Loss: 0.4148, Validation F1: 0.3782\n",
      "Epoch 24500/100000, Train Loss: 0.3215, Train F1: 0.4568, Validation Loss: 0.4150, Validation F1: 0.3774\n",
      "Epoch 24600/100000, Train Loss: 0.3219, Train F1: 0.4572, Validation Loss: 0.4150, Validation F1: 0.3774\n",
      "Epoch 24700/100000, Train Loss: 0.3223, Train F1: 0.4507, Validation Loss: 0.4151, Validation F1: 0.3769\n",
      "Epoch 24800/100000, Train Loss: 0.3213, Train F1: 0.4539, Validation Loss: 0.4152, Validation F1: 0.3812\n",
      "Epoch 24900/100000, Train Loss: 0.3227, Train F1: 0.4517, Validation Loss: 0.4153, Validation F1: 0.3812\n",
      "Epoch 25000/100000, Train Loss: 0.3209, Train F1: 0.4555, Validation Loss: 0.4152, Validation F1: 0.3802\n",
      "Epoch 25100/100000, Train Loss: 0.3218, Train F1: 0.4510, Validation Loss: 0.4151, Validation F1: 0.3815\n",
      "Epoch 25200/100000, Train Loss: 0.3219, Train F1: 0.4525, Validation Loss: 0.4153, Validation F1: 0.3807\n",
      "Epoch 25300/100000, Train Loss: 0.3210, Train F1: 0.4592, Validation Loss: 0.4153, Validation F1: 0.3815\n",
      "Epoch 25400/100000, Train Loss: 0.3209, Train F1: 0.4603, Validation Loss: 0.4155, Validation F1: 0.3823\n",
      "Epoch 25500/100000, Train Loss: 0.3213, Train F1: 0.4556, Validation Loss: 0.4155, Validation F1: 0.3850\n",
      "Epoch 25600/100000, Train Loss: 0.3210, Train F1: 0.4590, Validation Loss: 0.4153, Validation F1: 0.3826\n",
      "Epoch 25700/100000, Train Loss: 0.3197, Train F1: 0.4552, Validation Loss: 0.4156, Validation F1: 0.3850\n",
      "Epoch 25800/100000, Train Loss: 0.3206, Train F1: 0.4631, Validation Loss: 0.4155, Validation F1: 0.3850\n",
      "Epoch 25900/100000, Train Loss: 0.3198, Train F1: 0.4643, Validation Loss: 0.4155, Validation F1: 0.3858\n",
      "Epoch 26000/100000, Train Loss: 0.3202, Train F1: 0.4613, Validation Loss: 0.4156, Validation F1: 0.3850\n",
      "Epoch 26100/100000, Train Loss: 0.3202, Train F1: 0.4606, Validation Loss: 0.4156, Validation F1: 0.3858\n",
      "Epoch 26200/100000, Train Loss: 0.3202, Train F1: 0.4660, Validation Loss: 0.4157, Validation F1: 0.3858\n",
      "Epoch 26300/100000, Train Loss: 0.3189, Train F1: 0.4645, Validation Loss: 0.4159, Validation F1: 0.3867\n",
      "Epoch 26400/100000, Train Loss: 0.3197, Train F1: 0.4633, Validation Loss: 0.4157, Validation F1: 0.3858\n",
      "Epoch 26500/100000, Train Loss: 0.3187, Train F1: 0.4628, Validation Loss: 0.4158, Validation F1: 0.3862\n",
      "Epoch 26600/100000, Train Loss: 0.3191, Train F1: 0.4579, Validation Loss: 0.4159, Validation F1: 0.3875\n",
      "Epoch 26700/100000, Train Loss: 0.3184, Train F1: 0.4679, Validation Loss: 0.4160, Validation F1: 0.3880\n",
      "Epoch 26800/100000, Train Loss: 0.3191, Train F1: 0.4692, Validation Loss: 0.4160, Validation F1: 0.3880\n",
      "Epoch 26900/100000, Train Loss: 0.3184, Train F1: 0.4690, Validation Loss: 0.4160, Validation F1: 0.3905\n",
      "Epoch 27000/100000, Train Loss: 0.3177, Train F1: 0.4649, Validation Loss: 0.4160, Validation F1: 0.3905\n",
      "Epoch 27100/100000, Train Loss: 0.3184, Train F1: 0.4691, Validation Loss: 0.4160, Validation F1: 0.3900\n",
      "Epoch 27200/100000, Train Loss: 0.3186, Train F1: 0.4611, Validation Loss: 0.4162, Validation F1: 0.3905\n",
      "Epoch 27300/100000, Train Loss: 0.3175, Train F1: 0.4710, Validation Loss: 0.4161, Validation F1: 0.3912\n",
      "Epoch 27400/100000, Train Loss: 0.3168, Train F1: 0.4658, Validation Loss: 0.4163, Validation F1: 0.3954\n",
      "Epoch 27500/100000, Train Loss: 0.3174, Train F1: 0.4622, Validation Loss: 0.4162, Validation F1: 0.3954\n",
      "Epoch 27600/100000, Train Loss: 0.3180, Train F1: 0.4688, Validation Loss: 0.4164, Validation F1: 0.3954\n",
      "Epoch 27700/100000, Train Loss: 0.3174, Train F1: 0.4704, Validation Loss: 0.4162, Validation F1: 0.3948\n",
      "Epoch 27800/100000, Train Loss: 0.3165, Train F1: 0.4709, Validation Loss: 0.4164, Validation F1: 0.3953\n",
      "Epoch 27900/100000, Train Loss: 0.3173, Train F1: 0.4716, Validation Loss: 0.4165, Validation F1: 0.3973\n",
      "Epoch 28000/100000, Train Loss: 0.3175, Train F1: 0.4644, Validation Loss: 0.4164, Validation F1: 0.3986\n",
      "Epoch 28100/100000, Train Loss: 0.3171, Train F1: 0.4658, Validation Loss: 0.4164, Validation F1: 0.4018\n",
      "Epoch 28200/100000, Train Loss: 0.3154, Train F1: 0.4668, Validation Loss: 0.4166, Validation F1: 0.4030\n",
      "Epoch 28300/100000, Train Loss: 0.3164, Train F1: 0.4686, Validation Loss: 0.4166, Validation F1: 0.4042\n",
      "Epoch 28400/100000, Train Loss: 0.3162, Train F1: 0.4702, Validation Loss: 0.4167, Validation F1: 0.4019\n",
      "Epoch 28500/100000, Train Loss: 0.3167, Train F1: 0.4651, Validation Loss: 0.4169, Validation F1: 0.4016\n",
      "Epoch 28600/100000, Train Loss: 0.3166, Train F1: 0.4713, Validation Loss: 0.4166, Validation F1: 0.4042\n",
      "Epoch 28700/100000, Train Loss: 0.3164, Train F1: 0.4728, Validation Loss: 0.4167, Validation F1: 0.4030\n",
      "Epoch 28800/100000, Train Loss: 0.3156, Train F1: 0.4739, Validation Loss: 0.4170, Validation F1: 0.4035\n",
      "Epoch 28900/100000, Train Loss: 0.3150, Train F1: 0.4704, Validation Loss: 0.4170, Validation F1: 0.4035\n",
      "Epoch 29000/100000, Train Loss: 0.3155, Train F1: 0.4773, Validation Loss: 0.4170, Validation F1: 0.4080\n",
      "Epoch 29100/100000, Train Loss: 0.3149, Train F1: 0.4675, Validation Loss: 0.4170, Validation F1: 0.4093\n",
      "Epoch 29200/100000, Train Loss: 0.3157, Train F1: 0.4684, Validation Loss: 0.4170, Validation F1: 0.4107\n",
      "Epoch 29300/100000, Train Loss: 0.3149, Train F1: 0.4764, Validation Loss: 0.4171, Validation F1: 0.4107\n",
      "Epoch 29400/100000, Train Loss: 0.3149, Train F1: 0.4696, Validation Loss: 0.4172, Validation F1: 0.4107\n",
      "Epoch 29500/100000, Train Loss: 0.3152, Train F1: 0.4727, Validation Loss: 0.4174, Validation F1: 0.4115\n",
      "Epoch 29600/100000, Train Loss: 0.3140, Train F1: 0.4770, Validation Loss: 0.4174, Validation F1: 0.4143\n",
      "Epoch 29700/100000, Train Loss: 0.3151, Train F1: 0.4754, Validation Loss: 0.4174, Validation F1: 0.4138\n",
      "Epoch 29800/100000, Train Loss: 0.3149, Train F1: 0.4791, Validation Loss: 0.4175, Validation F1: 0.4129\n",
      "Epoch 29900/100000, Train Loss: 0.3147, Train F1: 0.4807, Validation Loss: 0.4175, Validation F1: 0.4124\n",
      "Epoch 30000/100000, Train Loss: 0.3144, Train F1: 0.4762, Validation Loss: 0.4175, Validation F1: 0.4112\n",
      "Epoch 30100/100000, Train Loss: 0.3144, Train F1: 0.4781, Validation Loss: 0.4178, Validation F1: 0.4155\n",
      "Epoch 30200/100000, Train Loss: 0.3141, Train F1: 0.4723, Validation Loss: 0.4177, Validation F1: 0.4148\n",
      "Epoch 30300/100000, Train Loss: 0.3136, Train F1: 0.4742, Validation Loss: 0.4177, Validation F1: 0.4138\n",
      "Epoch 30400/100000, Train Loss: 0.3140, Train F1: 0.4736, Validation Loss: 0.4178, Validation F1: 0.4143\n",
      "Epoch 30500/100000, Train Loss: 0.3149, Train F1: 0.4814, Validation Loss: 0.4178, Validation F1: 0.4138\n",
      "Epoch 30600/100000, Train Loss: 0.3126, Train F1: 0.4800, Validation Loss: 0.4180, Validation F1: 0.4172\n",
      "Epoch 30700/100000, Train Loss: 0.3135, Train F1: 0.4824, Validation Loss: 0.4181, Validation F1: 0.4167\n",
      "Epoch 30800/100000, Train Loss: 0.3132, Train F1: 0.4817, Validation Loss: 0.4182, Validation F1: 0.4167\n",
      "Epoch 30900/100000, Train Loss: 0.3134, Train F1: 0.4808, Validation Loss: 0.4181, Validation F1: 0.4157\n",
      "Epoch 31000/100000, Train Loss: 0.3136, Train F1: 0.4817, Validation Loss: 0.4183, Validation F1: 0.4187\n",
      "Epoch 31100/100000, Train Loss: 0.3117, Train F1: 0.4819, Validation Loss: 0.4184, Validation F1: 0.4197\n",
      "Epoch 31200/100000, Train Loss: 0.3114, Train F1: 0.4814, Validation Loss: 0.4183, Validation F1: 0.4182\n",
      "Epoch 31300/100000, Train Loss: 0.3125, Train F1: 0.4835, Validation Loss: 0.4182, Validation F1: 0.4176\n",
      "Epoch 31400/100000, Train Loss: 0.3120, Train F1: 0.4907, Validation Loss: 0.4184, Validation F1: 0.4181\n",
      "Epoch 31500/100000, Train Loss: 0.3104, Train F1: 0.4901, Validation Loss: 0.4185, Validation F1: 0.4169\n",
      "Epoch 31600/100000, Train Loss: 0.3116, Train F1: 0.4855, Validation Loss: 0.4185, Validation F1: 0.4164\n",
      "Epoch 31700/100000, Train Loss: 0.3116, Train F1: 0.4818, Validation Loss: 0.4188, Validation F1: 0.4179\n",
      "Epoch 31800/100000, Train Loss: 0.3114, Train F1: 0.4833, Validation Loss: 0.4189, Validation F1: 0.4163\n",
      "Epoch 31900/100000, Train Loss: 0.3107, Train F1: 0.4838, Validation Loss: 0.4187, Validation F1: 0.4148\n",
      "Epoch 32000/100000, Train Loss: 0.3102, Train F1: 0.4896, Validation Loss: 0.4188, Validation F1: 0.4143\n",
      "Epoch 32100/100000, Train Loss: 0.3108, Train F1: 0.4861, Validation Loss: 0.4190, Validation F1: 0.4158\n",
      "Epoch 32200/100000, Train Loss: 0.3105, Train F1: 0.4836, Validation Loss: 0.4188, Validation F1: 0.4157\n",
      "Epoch 32300/100000, Train Loss: 0.3118, Train F1: 0.4908, Validation Loss: 0.4192, Validation F1: 0.4140\n",
      "Epoch 32400/100000, Train Loss: 0.3101, Train F1: 0.4893, Validation Loss: 0.4190, Validation F1: 0.4152\n",
      "Epoch 32500/100000, Train Loss: 0.3100, Train F1: 0.4879, Validation Loss: 0.4193, Validation F1: 0.4135\n",
      "Epoch 32600/100000, Train Loss: 0.3096, Train F1: 0.4918, Validation Loss: 0.4192, Validation F1: 0.4135\n",
      "Epoch 32700/100000, Train Loss: 0.3096, Train F1: 0.4842, Validation Loss: 0.4194, Validation F1: 0.4135\n",
      "Epoch 32800/100000, Train Loss: 0.3099, Train F1: 0.4879, Validation Loss: 0.4193, Validation F1: 0.4148\n",
      "Epoch 32900/100000, Train Loss: 0.3106, Train F1: 0.4916, Validation Loss: 0.4195, Validation F1: 0.4135\n",
      "Epoch 33000/100000, Train Loss: 0.3100, Train F1: 0.4958, Validation Loss: 0.4199, Validation F1: 0.4129\n",
      "Epoch 33100/100000, Train Loss: 0.3089, Train F1: 0.4940, Validation Loss: 0.4196, Validation F1: 0.4138\n",
      "Epoch 33200/100000, Train Loss: 0.3101, Train F1: 0.4972, Validation Loss: 0.4199, Validation F1: 0.4143\n",
      "Epoch 33300/100000, Train Loss: 0.3094, Train F1: 0.4914, Validation Loss: 0.4198, Validation F1: 0.4156\n",
      "Epoch 33400/100000, Train Loss: 0.3094, Train F1: 0.4894, Validation Loss: 0.4200, Validation F1: 0.4156\n",
      "Epoch 33500/100000, Train Loss: 0.3093, Train F1: 0.4924, Validation Loss: 0.4200, Validation F1: 0.4185\n",
      "Epoch 33600/100000, Train Loss: 0.3096, Train F1: 0.4926, Validation Loss: 0.4201, Validation F1: 0.4198\n",
      "Epoch 33700/100000, Train Loss: 0.3099, Train F1: 0.4862, Validation Loss: 0.4201, Validation F1: 0.4210\n",
      "Epoch 33800/100000, Train Loss: 0.3087, Train F1: 0.4985, Validation Loss: 0.4203, Validation F1: 0.4210\n",
      "Epoch 33900/100000, Train Loss: 0.3083, Train F1: 0.4910, Validation Loss: 0.4203, Validation F1: 0.4217\n",
      "Epoch 34000/100000, Train Loss: 0.3072, Train F1: 0.4941, Validation Loss: 0.4201, Validation F1: 0.4214\n",
      "Epoch 34100/100000, Train Loss: 0.3080, Train F1: 0.4877, Validation Loss: 0.4203, Validation F1: 0.4212\n",
      "Epoch 34200/100000, Train Loss: 0.3081, Train F1: 0.4941, Validation Loss: 0.4203, Validation F1: 0.4214\n",
      "Epoch 34300/100000, Train Loss: 0.3085, Train F1: 0.4953, Validation Loss: 0.4204, Validation F1: 0.4195\n",
      "Epoch 34400/100000, Train Loss: 0.3080, Train F1: 0.4933, Validation Loss: 0.4206, Validation F1: 0.4199\n",
      "Epoch 34500/100000, Train Loss: 0.3072, Train F1: 0.4979, Validation Loss: 0.4208, Validation F1: 0.4183\n",
      "Epoch 34600/100000, Train Loss: 0.3073, Train F1: 0.5042, Validation Loss: 0.4209, Validation F1: 0.4178\n",
      "Epoch 34700/100000, Train Loss: 0.3079, Train F1: 0.5001, Validation Loss: 0.4209, Validation F1: 0.4185\n",
      "Epoch 34800/100000, Train Loss: 0.3070, Train F1: 0.4968, Validation Loss: 0.4209, Validation F1: 0.4185\n",
      "Epoch 34900/100000, Train Loss: 0.3071, Train F1: 0.5026, Validation Loss: 0.4212, Validation F1: 0.4163\n",
      "Epoch 35000/100000, Train Loss: 0.3074, Train F1: 0.4957, Validation Loss: 0.4214, Validation F1: 0.4168\n",
      "Epoch 35100/100000, Train Loss: 0.3071, Train F1: 0.5006, Validation Loss: 0.4213, Validation F1: 0.4212\n",
      "Epoch 35200/100000, Train Loss: 0.3076, Train F1: 0.5027, Validation Loss: 0.4215, Validation F1: 0.4192\n",
      "Epoch 35300/100000, Train Loss: 0.3061, Train F1: 0.4990, Validation Loss: 0.4216, Validation F1: 0.4192\n",
      "Epoch 35400/100000, Train Loss: 0.3075, Train F1: 0.5022, Validation Loss: 0.4216, Validation F1: 0.4247\n",
      "Epoch 35500/100000, Train Loss: 0.3062, Train F1: 0.5002, Validation Loss: 0.4216, Validation F1: 0.4223\n",
      "Epoch 35600/100000, Train Loss: 0.3067, Train F1: 0.4987, Validation Loss: 0.4218, Validation F1: 0.4245\n",
      "Epoch 35700/100000, Train Loss: 0.3068, Train F1: 0.4989, Validation Loss: 0.4218, Validation F1: 0.4247\n",
      "Epoch 35800/100000, Train Loss: 0.3057, Train F1: 0.5041, Validation Loss: 0.4218, Validation F1: 0.4273\n",
      "Epoch 35900/100000, Train Loss: 0.3050, Train F1: 0.5047, Validation Loss: 0.4218, Validation F1: 0.4262\n",
      "Epoch 36000/100000, Train Loss: 0.3046, Train F1: 0.4992, Validation Loss: 0.4223, Validation F1: 0.4256\n",
      "Epoch 36100/100000, Train Loss: 0.3060, Train F1: 0.5045, Validation Loss: 0.4223, Validation F1: 0.4246\n",
      "Epoch 36200/100000, Train Loss: 0.3054, Train F1: 0.5105, Validation Loss: 0.4225, Validation F1: 0.4241\n",
      "Epoch 36300/100000, Train Loss: 0.3040, Train F1: 0.5068, Validation Loss: 0.4226, Validation F1: 0.4246\n",
      "Epoch 36400/100000, Train Loss: 0.3050, Train F1: 0.5004, Validation Loss: 0.4226, Validation F1: 0.4269\n",
      "Epoch 36500/100000, Train Loss: 0.3055, Train F1: 0.5069, Validation Loss: 0.4227, Validation F1: 0.4274\n",
      "Epoch 36600/100000, Train Loss: 0.3046, Train F1: 0.5034, Validation Loss: 0.4230, Validation F1: 0.4280\n",
      "Epoch 36700/100000, Train Loss: 0.3045, Train F1: 0.5078, Validation Loss: 0.4230, Validation F1: 0.4274\n",
      "Epoch 36800/100000, Train Loss: 0.3039, Train F1: 0.5103, Validation Loss: 0.4232, Validation F1: 0.4274\n",
      "Epoch 36900/100000, Train Loss: 0.3039, Train F1: 0.5072, Validation Loss: 0.4230, Validation F1: 0.4286\n",
      "Epoch 37000/100000, Train Loss: 0.3035, Train F1: 0.5130, Validation Loss: 0.4232, Validation F1: 0.4286\n",
      "Epoch 37100/100000, Train Loss: 0.3030, Train F1: 0.5148, Validation Loss: 0.4233, Validation F1: 0.4281\n",
      "Epoch 37200/100000, Train Loss: 0.3038, Train F1: 0.5081, Validation Loss: 0.4234, Validation F1: 0.4272\n",
      "Epoch 37300/100000, Train Loss: 0.3026, Train F1: 0.5114, Validation Loss: 0.4236, Validation F1: 0.4300\n",
      "Epoch 37400/100000, Train Loss: 0.3035, Train F1: 0.5091, Validation Loss: 0.4237, Validation F1: 0.4272\n",
      "Epoch 37500/100000, Train Loss: 0.3030, Train F1: 0.5040, Validation Loss: 0.4237, Validation F1: 0.4233\n",
      "Epoch 37600/100000, Train Loss: 0.3028, Train F1: 0.5070, Validation Loss: 0.4238, Validation F1: 0.4250\n",
      "Epoch 37700/100000, Train Loss: 0.3024, Train F1: 0.5113, Validation Loss: 0.4239, Validation F1: 0.4222\n",
      "Epoch 37800/100000, Train Loss: 0.3040, Train F1: 0.5086, Validation Loss: 0.4239, Validation F1: 0.4245\n",
      "Epoch 37900/100000, Train Loss: 0.3021, Train F1: 0.5134, Validation Loss: 0.4244, Validation F1: 0.4215\n",
      "Epoch 38000/100000, Train Loss: 0.3029, Train F1: 0.5170, Validation Loss: 0.4243, Validation F1: 0.4222\n",
      "Epoch 38100/100000, Train Loss: 0.3014, Train F1: 0.5130, Validation Loss: 0.4244, Validation F1: 0.4222\n",
      "Epoch 38200/100000, Train Loss: 0.3013, Train F1: 0.5172, Validation Loss: 0.4243, Validation F1: 0.4241\n",
      "Epoch 38300/100000, Train Loss: 0.3023, Train F1: 0.5103, Validation Loss: 0.4244, Validation F1: 0.4241\n",
      "Epoch 38400/100000, Train Loss: 0.3013, Train F1: 0.5165, Validation Loss: 0.4247, Validation F1: 0.4240\n",
      "Epoch 38500/100000, Train Loss: 0.3010, Train F1: 0.5096, Validation Loss: 0.4248, Validation F1: 0.4215\n",
      "Epoch 38600/100000, Train Loss: 0.3028, Train F1: 0.5105, Validation Loss: 0.4251, Validation F1: 0.4221\n",
      "Epoch 38700/100000, Train Loss: 0.3006, Train F1: 0.5171, Validation Loss: 0.4249, Validation F1: 0.4215\n",
      "Epoch 38800/100000, Train Loss: 0.3011, Train F1: 0.5164, Validation Loss: 0.4251, Validation F1: 0.4215\n",
      "Epoch 38900/100000, Train Loss: 0.3010, Train F1: 0.5152, Validation Loss: 0.4254, Validation F1: 0.4215\n",
      "Epoch 39000/100000, Train Loss: 0.3004, Train F1: 0.5210, Validation Loss: 0.4254, Validation F1: 0.4215\n",
      "Epoch 39100/100000, Train Loss: 0.3004, Train F1: 0.5159, Validation Loss: 0.4257, Validation F1: 0.4227\n",
      "Epoch 39200/100000, Train Loss: 0.2996, Train F1: 0.5148, Validation Loss: 0.4258, Validation F1: 0.4221\n",
      "Epoch 39300/100000, Train Loss: 0.3006, Train F1: 0.5209, Validation Loss: 0.4259, Validation F1: 0.4227\n",
      "Epoch 39400/100000, Train Loss: 0.3014, Train F1: 0.5202, Validation Loss: 0.4259, Validation F1: 0.4227\n",
      "Epoch 39500/100000, Train Loss: 0.3006, Train F1: 0.5115, Validation Loss: 0.4258, Validation F1: 0.4227\n",
      "Epoch 39600/100000, Train Loss: 0.2998, Train F1: 0.5121, Validation Loss: 0.4261, Validation F1: 0.4227\n",
      "Epoch 39700/100000, Train Loss: 0.3007, Train F1: 0.5115, Validation Loss: 0.4262, Validation F1: 0.4232\n",
      "Epoch 39800/100000, Train Loss: 0.3007, Train F1: 0.5138, Validation Loss: 0.4266, Validation F1: 0.4226\n",
      "Epoch 39900/100000, Train Loss: 0.2986, Train F1: 0.5189, Validation Loss: 0.4265, Validation F1: 0.4232\n",
      "Epoch 40000/100000, Train Loss: 0.3002, Train F1: 0.5197, Validation Loss: 0.4266, Validation F1: 0.4232\n",
      "Epoch 40100/100000, Train Loss: 0.2986, Train F1: 0.5191, Validation Loss: 0.4269, Validation F1: 0.4231\n",
      "Epoch 40200/100000, Train Loss: 0.2992, Train F1: 0.5171, Validation Loss: 0.4269, Validation F1: 0.4231\n",
      "Epoch 40300/100000, Train Loss: 0.2999, Train F1: 0.5172, Validation Loss: 0.4267, Validation F1: 0.4233\n",
      "Epoch 40400/100000, Train Loss: 0.2989, Train F1: 0.5178, Validation Loss: 0.4273, Validation F1: 0.4231\n",
      "Epoch 40500/100000, Train Loss: 0.3008, Train F1: 0.5254, Validation Loss: 0.4276, Validation F1: 0.4231\n",
      "Epoch 40600/100000, Train Loss: 0.2987, Train F1: 0.5256, Validation Loss: 0.4277, Validation F1: 0.4243\n",
      "Epoch 40700/100000, Train Loss: 0.2995, Train F1: 0.5246, Validation Loss: 0.4277, Validation F1: 0.4243\n",
      "Epoch 40800/100000, Train Loss: 0.2990, Train F1: 0.5235, Validation Loss: 0.4277, Validation F1: 0.4238\n",
      "Epoch 40900/100000, Train Loss: 0.2983, Train F1: 0.5188, Validation Loss: 0.4281, Validation F1: 0.4238\n",
      "Epoch 41000/100000, Train Loss: 0.2979, Train F1: 0.5129, Validation Loss: 0.4283, Validation F1: 0.4243\n",
      "Epoch 41100/100000, Train Loss: 0.2984, Train F1: 0.5231, Validation Loss: 0.4284, Validation F1: 0.4238\n",
      "Epoch 41200/100000, Train Loss: 0.2982, Train F1: 0.5254, Validation Loss: 0.4285, Validation F1: 0.4238\n",
      "Epoch 41300/100000, Train Loss: 0.2983, Train F1: 0.5160, Validation Loss: 0.4284, Validation F1: 0.4250\n",
      "Epoch 41400/100000, Train Loss: 0.2976, Train F1: 0.5244, Validation Loss: 0.4285, Validation F1: 0.4228\n",
      "Epoch 41500/100000, Train Loss: 0.2991, Train F1: 0.5174, Validation Loss: 0.4286, Validation F1: 0.4248\n",
      "Epoch 41600/100000, Train Loss: 0.2969, Train F1: 0.5258, Validation Loss: 0.4290, Validation F1: 0.4267\n",
      "Epoch 41700/100000, Train Loss: 0.2964, Train F1: 0.5248, Validation Loss: 0.4288, Validation F1: 0.4234\n",
      "Epoch 41800/100000, Train Loss: 0.2969, Train F1: 0.5257, Validation Loss: 0.4291, Validation F1: 0.4210\n",
      "Epoch 41900/100000, Train Loss: 0.2967, Train F1: 0.5242, Validation Loss: 0.4294, Validation F1: 0.4227\n",
      "Epoch 42000/100000, Train Loss: 0.2974, Train F1: 0.5230, Validation Loss: 0.4296, Validation F1: 0.4232\n",
      "Epoch 42100/100000, Train Loss: 0.2965, Train F1: 0.5241, Validation Loss: 0.4298, Validation F1: 0.4232\n",
      "Epoch 42200/100000, Train Loss: 0.2981, Train F1: 0.5207, Validation Loss: 0.4297, Validation F1: 0.4247\n",
      "Epoch 42300/100000, Train Loss: 0.2966, Train F1: 0.5312, Validation Loss: 0.4299, Validation F1: 0.4249\n",
      "Epoch 42400/100000, Train Loss: 0.2977, Train F1: 0.5223, Validation Loss: 0.4302, Validation F1: 0.4234\n",
      "Epoch 42500/100000, Train Loss: 0.2973, Train F1: 0.5208, Validation Loss: 0.4302, Validation F1: 0.4246\n",
      "Epoch 42600/100000, Train Loss: 0.2971, Train F1: 0.5294, Validation Loss: 0.4302, Validation F1: 0.4246\n",
      "Epoch 42700/100000, Train Loss: 0.2954, Train F1: 0.5270, Validation Loss: 0.4303, Validation F1: 0.4232\n",
      "Epoch 42800/100000, Train Loss: 0.2955, Train F1: 0.5298, Validation Loss: 0.4305, Validation F1: 0.4232\n",
      "Epoch 42900/100000, Train Loss: 0.2958, Train F1: 0.5206, Validation Loss: 0.4306, Validation F1: 0.4260\n",
      "Epoch 43000/100000, Train Loss: 0.2955, Train F1: 0.5319, Validation Loss: 0.4309, Validation F1: 0.4260\n",
      "Epoch 43100/100000, Train Loss: 0.2962, Train F1: 0.5292, Validation Loss: 0.4312, Validation F1: 0.4270\n",
      "Epoch 43200/100000, Train Loss: 0.2953, Train F1: 0.5303, Validation Loss: 0.4312, Validation F1: 0.4253\n",
      "Epoch 43300/100000, Train Loss: 0.2954, Train F1: 0.5250, Validation Loss: 0.4316, Validation F1: 0.4253\n",
      "Epoch 43400/100000, Train Loss: 0.2944, Train F1: 0.5322, Validation Loss: 0.4312, Validation F1: 0.4260\n",
      "Epoch 43500/100000, Train Loss: 0.2946, Train F1: 0.5281, Validation Loss: 0.4319, Validation F1: 0.4253\n",
      "Epoch 43600/100000, Train Loss: 0.2953, Train F1: 0.5195, Validation Loss: 0.4322, Validation F1: 0.4263\n",
      "Epoch 43700/100000, Train Loss: 0.2948, Train F1: 0.5341, Validation Loss: 0.4321, Validation F1: 0.4262\n",
      "Epoch 43800/100000, Train Loss: 0.2934, Train F1: 0.5309, Validation Loss: 0.4322, Validation F1: 0.4288\n",
      "Epoch 43900/100000, Train Loss: 0.2949, Train F1: 0.5313, Validation Loss: 0.4324, Validation F1: 0.4276\n",
      "Epoch 44000/100000, Train Loss: 0.2957, Train F1: 0.5277, Validation Loss: 0.4323, Validation F1: 0.4283\n",
      "Epoch 44100/100000, Train Loss: 0.2945, Train F1: 0.5290, Validation Loss: 0.4327, Validation F1: 0.4288\n",
      "Epoch 44200/100000, Train Loss: 0.2936, Train F1: 0.5294, Validation Loss: 0.4330, Validation F1: 0.4282\n",
      "Epoch 44300/100000, Train Loss: 0.2938, Train F1: 0.5304, Validation Loss: 0.4330, Validation F1: 0.4315\n",
      "Epoch 44400/100000, Train Loss: 0.2938, Train F1: 0.5282, Validation Loss: 0.4334, Validation F1: 0.4282\n",
      "Epoch 44500/100000, Train Loss: 0.2932, Train F1: 0.5297, Validation Loss: 0.4331, Validation F1: 0.4300\n",
      "Epoch 44600/100000, Train Loss: 0.2942, Train F1: 0.5286, Validation Loss: 0.4334, Validation F1: 0.4305\n",
      "Epoch 44700/100000, Train Loss: 0.2938, Train F1: 0.5304, Validation Loss: 0.4337, Validation F1: 0.4305\n",
      "Epoch 44800/100000, Train Loss: 0.2933, Train F1: 0.5298, Validation Loss: 0.4338, Validation F1: 0.4305\n",
      "Epoch 44900/100000, Train Loss: 0.2937, Train F1: 0.5354, Validation Loss: 0.4341, Validation F1: 0.4305\n",
      "Epoch 45000/100000, Train Loss: 0.2934, Train F1: 0.5331, Validation Loss: 0.4341, Validation F1: 0.4300\n",
      "Epoch 45100/100000, Train Loss: 0.2922, Train F1: 0.5283, Validation Loss: 0.4342, Validation F1: 0.4327\n",
      "Epoch 45200/100000, Train Loss: 0.2923, Train F1: 0.5335, Validation Loss: 0.4346, Validation F1: 0.4332\n",
      "Epoch 45300/100000, Train Loss: 0.2933, Train F1: 0.5312, Validation Loss: 0.4344, Validation F1: 0.4336\n",
      "Epoch 45400/100000, Train Loss: 0.2929, Train F1: 0.5405, Validation Loss: 0.4348, Validation F1: 0.4330\n",
      "Epoch 45500/100000, Train Loss: 0.2914, Train F1: 0.5332, Validation Loss: 0.4348, Validation F1: 0.4334\n",
      "Epoch 45600/100000, Train Loss: 0.2926, Train F1: 0.5321, Validation Loss: 0.4351, Validation F1: 0.4320\n",
      "Epoch 45700/100000, Train Loss: 0.2922, Train F1: 0.5370, Validation Loss: 0.4353, Validation F1: 0.4320\n",
      "Epoch 45800/100000, Train Loss: 0.2921, Train F1: 0.5343, Validation Loss: 0.4353, Validation F1: 0.4334\n",
      "Epoch 45900/100000, Train Loss: 0.2908, Train F1: 0.5416, Validation Loss: 0.4355, Validation F1: 0.4334\n",
      "Epoch 46000/100000, Train Loss: 0.2914, Train F1: 0.5339, Validation Loss: 0.4358, Validation F1: 0.4334\n",
      "Epoch 46100/100000, Train Loss: 0.2911, Train F1: 0.5326, Validation Loss: 0.4357, Validation F1: 0.4340\n",
      "Epoch 46200/100000, Train Loss: 0.2915, Train F1: 0.5380, Validation Loss: 0.4357, Validation F1: 0.4373\n",
      "Epoch 46300/100000, Train Loss: 0.2914, Train F1: 0.5415, Validation Loss: 0.4361, Validation F1: 0.4373\n",
      "Epoch 46400/100000, Train Loss: 0.2905, Train F1: 0.5368, Validation Loss: 0.4364, Validation F1: 0.4373\n",
      "Epoch 46500/100000, Train Loss: 0.2920, Train F1: 0.5416, Validation Loss: 0.4369, Validation F1: 0.4371\n",
      "Epoch 46600/100000, Train Loss: 0.2903, Train F1: 0.5402, Validation Loss: 0.4369, Validation F1: 0.4361\n",
      "Epoch 46700/100000, Train Loss: 0.2902, Train F1: 0.5372, Validation Loss: 0.4369, Validation F1: 0.4373\n",
      "Epoch 46800/100000, Train Loss: 0.2897, Train F1: 0.5455, Validation Loss: 0.4373, Validation F1: 0.4339\n",
      "Epoch 46900/100000, Train Loss: 0.2903, Train F1: 0.5401, Validation Loss: 0.4372, Validation F1: 0.4365\n",
      "Epoch 47000/100000, Train Loss: 0.2901, Train F1: 0.5435, Validation Loss: 0.4373, Validation F1: 0.4386\n",
      "Epoch 47100/100000, Train Loss: 0.2896, Train F1: 0.5436, Validation Loss: 0.4378, Validation F1: 0.4351\n",
      "Epoch 47200/100000, Train Loss: 0.2896, Train F1: 0.5459, Validation Loss: 0.4377, Validation F1: 0.4365\n",
      "Epoch 47300/100000, Train Loss: 0.2902, Train F1: 0.5404, Validation Loss: 0.4377, Validation F1: 0.4386\n",
      "Epoch 47400/100000, Train Loss: 0.2906, Train F1: 0.5368, Validation Loss: 0.4383, Validation F1: 0.4365\n",
      "Epoch 47500/100000, Train Loss: 0.2914, Train F1: 0.5421, Validation Loss: 0.4384, Validation F1: 0.4378\n",
      "Epoch 47600/100000, Train Loss: 0.2897, Train F1: 0.5376, Validation Loss: 0.4387, Validation F1: 0.4378\n",
      "Epoch 47700/100000, Train Loss: 0.2893, Train F1: 0.5361, Validation Loss: 0.4389, Validation F1: 0.4371\n",
      "Epoch 47800/100000, Train Loss: 0.2907, Train F1: 0.5421, Validation Loss: 0.4388, Validation F1: 0.4365\n",
      "Epoch 47900/100000, Train Loss: 0.2900, Train F1: 0.5384, Validation Loss: 0.4390, Validation F1: 0.4392\n",
      "Epoch 48000/100000, Train Loss: 0.2891, Train F1: 0.5449, Validation Loss: 0.4391, Validation F1: 0.4392\n",
      "Epoch 48100/100000, Train Loss: 0.2899, Train F1: 0.5395, Validation Loss: 0.4394, Validation F1: 0.4338\n",
      "Epoch 48200/100000, Train Loss: 0.2891, Train F1: 0.5452, Validation Loss: 0.4396, Validation F1: 0.4365\n",
      "Epoch 48300/100000, Train Loss: 0.2895, Train F1: 0.5391, Validation Loss: 0.4400, Validation F1: 0.4339\n",
      "Epoch 48400/100000, Train Loss: 0.2889, Train F1: 0.5418, Validation Loss: 0.4398, Validation F1: 0.4365\n",
      "Epoch 48500/100000, Train Loss: 0.2879, Train F1: 0.5490, Validation Loss: 0.4402, Validation F1: 0.4365\n",
      "Epoch 48600/100000, Train Loss: 0.2874, Train F1: 0.5485, Validation Loss: 0.4403, Validation F1: 0.4365\n",
      "Epoch 48700/100000, Train Loss: 0.2889, Train F1: 0.5442, Validation Loss: 0.4404, Validation F1: 0.4365\n",
      "Epoch 48800/100000, Train Loss: 0.2884, Train F1: 0.5428, Validation Loss: 0.4410, Validation F1: 0.4353\n",
      "Epoch 48900/100000, Train Loss: 0.2884, Train F1: 0.5427, Validation Loss: 0.4410, Validation F1: 0.4326\n",
      "Epoch 49000/100000, Train Loss: 0.2875, Train F1: 0.5440, Validation Loss: 0.4412, Validation F1: 0.4353\n",
      "Epoch 49100/100000, Train Loss: 0.2879, Train F1: 0.5460, Validation Loss: 0.4415, Validation F1: 0.4332\n",
      "Epoch 49200/100000, Train Loss: 0.2882, Train F1: 0.5446, Validation Loss: 0.4419, Validation F1: 0.4347\n",
      "Epoch 49300/100000, Train Loss: 0.2879, Train F1: 0.5430, Validation Loss: 0.4417, Validation F1: 0.4321\n",
      "Epoch 49400/100000, Train Loss: 0.2873, Train F1: 0.5498, Validation Loss: 0.4418, Validation F1: 0.4321\n",
      "Epoch 49500/100000, Train Loss: 0.2876, Train F1: 0.5385, Validation Loss: 0.4421, Validation F1: 0.4321\n",
      "Epoch 49600/100000, Train Loss: 0.2869, Train F1: 0.5416, Validation Loss: 0.4422, Validation F1: 0.4321\n",
      "Epoch 49700/100000, Train Loss: 0.2885, Train F1: 0.5470, Validation Loss: 0.4425, Validation F1: 0.4309\n",
      "Epoch 49800/100000, Train Loss: 0.2864, Train F1: 0.5455, Validation Loss: 0.4424, Validation F1: 0.4326\n",
      "Epoch 49900/100000, Train Loss: 0.2873, Train F1: 0.5429, Validation Loss: 0.4426, Validation F1: 0.4312\n",
      "Epoch 50000/100000, Train Loss: 0.2874, Train F1: 0.5490, Validation Loss: 0.4424, Validation F1: 0.4344\n",
      "Epoch 50100/100000, Train Loss: 0.2869, Train F1: 0.5541, Validation Loss: 0.4431, Validation F1: 0.4321\n",
      "Epoch 50200/100000, Train Loss: 0.2853, Train F1: 0.5478, Validation Loss: 0.4433, Validation F1: 0.4307\n",
      "Epoch 50300/100000, Train Loss: 0.2870, Train F1: 0.5432, Validation Loss: 0.4433, Validation F1: 0.4321\n",
      "Epoch 50400/100000, Train Loss: 0.2852, Train F1: 0.5483, Validation Loss: 0.4439, Validation F1: 0.4295\n",
      "Epoch 50500/100000, Train Loss: 0.2860, Train F1: 0.5549, Validation Loss: 0.4440, Validation F1: 0.4309\n",
      "Epoch 50600/100000, Train Loss: 0.2869, Train F1: 0.5550, Validation Loss: 0.4440, Validation F1: 0.4365\n",
      "Epoch 50700/100000, Train Loss: 0.2867, Train F1: 0.5479, Validation Loss: 0.4444, Validation F1: 0.4321\n",
      "Epoch 50800/100000, Train Loss: 0.2862, Train F1: 0.5528, Validation Loss: 0.4446, Validation F1: 0.4309\n",
      "Epoch 50900/100000, Train Loss: 0.2860, Train F1: 0.5448, Validation Loss: 0.4446, Validation F1: 0.4332\n",
      "Epoch 51000/100000, Train Loss: 0.2860, Train F1: 0.5452, Validation Loss: 0.4452, Validation F1: 0.4328\n",
      "Epoch 51100/100000, Train Loss: 0.2848, Train F1: 0.5610, Validation Loss: 0.4448, Validation F1: 0.4344\n",
      "Epoch 51200/100000, Train Loss: 0.2855, Train F1: 0.5518, Validation Loss: 0.4452, Validation F1: 0.4332\n",
      "Epoch 51300/100000, Train Loss: 0.2861, Train F1: 0.5487, Validation Loss: 0.4454, Validation F1: 0.4348\n",
      "Epoch 51400/100000, Train Loss: 0.2847, Train F1: 0.5502, Validation Loss: 0.4456, Validation F1: 0.4327\n",
      "Epoch 51500/100000, Train Loss: 0.2847, Train F1: 0.5548, Validation Loss: 0.4461, Validation F1: 0.4326\n",
      "Epoch 51600/100000, Train Loss: 0.2852, Train F1: 0.5560, Validation Loss: 0.4459, Validation F1: 0.4334\n",
      "Epoch 51700/100000, Train Loss: 0.2844, Train F1: 0.5480, Validation Loss: 0.4460, Validation F1: 0.4338\n",
      "Epoch 51800/100000, Train Loss: 0.2845, Train F1: 0.5508, Validation Loss: 0.4467, Validation F1: 0.4314\n",
      "Epoch 51900/100000, Train Loss: 0.2842, Train F1: 0.5532, Validation Loss: 0.4471, Validation F1: 0.4287\n",
      "Epoch 52000/100000, Train Loss: 0.2850, Train F1: 0.5563, Validation Loss: 0.4471, Validation F1: 0.4302\n",
      "Epoch 52100/100000, Train Loss: 0.2856, Train F1: 0.5528, Validation Loss: 0.4464, Validation F1: 0.4346\n",
      "Epoch 52200/100000, Train Loss: 0.2845, Train F1: 0.5531, Validation Loss: 0.4475, Validation F1: 0.4312\n",
      "Epoch 52300/100000, Train Loss: 0.2849, Train F1: 0.5498, Validation Loss: 0.4474, Validation F1: 0.4308\n",
      "Epoch 52400/100000, Train Loss: 0.2850, Train F1: 0.5455, Validation Loss: 0.4476, Validation F1: 0.4306\n",
      "Epoch 52500/100000, Train Loss: 0.2833, Train F1: 0.5491, Validation Loss: 0.4477, Validation F1: 0.4306\n",
      "Epoch 52600/100000, Train Loss: 0.2843, Train F1: 0.5510, Validation Loss: 0.4480, Validation F1: 0.4299\n",
      "Epoch 52700/100000, Train Loss: 0.2830, Train F1: 0.5489, Validation Loss: 0.4482, Validation F1: 0.4299\n",
      "Epoch 52800/100000, Train Loss: 0.2833, Train F1: 0.5542, Validation Loss: 0.4483, Validation F1: 0.4294\n",
      "Epoch 52900/100000, Train Loss: 0.2845, Train F1: 0.5532, Validation Loss: 0.4488, Validation F1: 0.4332\n",
      "Epoch 53000/100000, Train Loss: 0.2826, Train F1: 0.5536, Validation Loss: 0.4490, Validation F1: 0.4318\n",
      "Epoch 53100/100000, Train Loss: 0.2820, Train F1: 0.5520, Validation Loss: 0.4493, Validation F1: 0.4332\n",
      "Epoch 53200/100000, Train Loss: 0.2824, Train F1: 0.5557, Validation Loss: 0.4493, Validation F1: 0.4321\n",
      "Epoch 53300/100000, Train Loss: 0.2840, Train F1: 0.5500, Validation Loss: 0.4494, Validation F1: 0.4321\n",
      "Epoch 53400/100000, Train Loss: 0.2837, Train F1: 0.5505, Validation Loss: 0.4500, Validation F1: 0.4332\n",
      "Epoch 53500/100000, Train Loss: 0.2825, Train F1: 0.5548, Validation Loss: 0.4498, Validation F1: 0.4321\n",
      "Epoch 53600/100000, Train Loss: 0.2818, Train F1: 0.5600, Validation Loss: 0.4497, Validation F1: 0.4321\n",
      "Epoch 53700/100000, Train Loss: 0.2820, Train F1: 0.5557, Validation Loss: 0.4503, Validation F1: 0.4314\n",
      "Epoch 53800/100000, Train Loss: 0.2818, Train F1: 0.5627, Validation Loss: 0.4507, Validation F1: 0.4320\n",
      "Epoch 53900/100000, Train Loss: 0.2830, Train F1: 0.5606, Validation Loss: 0.4513, Validation F1: 0.4325\n",
      "Epoch 54000/100000, Train Loss: 0.2823, Train F1: 0.5565, Validation Loss: 0.4511, Validation F1: 0.4325\n",
      "Epoch 54100/100000, Train Loss: 0.2828, Train F1: 0.5591, Validation Loss: 0.4512, Validation F1: 0.4314\n",
      "Epoch 54200/100000, Train Loss: 0.2825, Train F1: 0.5605, Validation Loss: 0.4517, Validation F1: 0.4320\n",
      "Epoch 54300/100000, Train Loss: 0.2811, Train F1: 0.5680, Validation Loss: 0.4517, Validation F1: 0.4299\n",
      "Epoch 54400/100000, Train Loss: 0.2807, Train F1: 0.5547, Validation Loss: 0.4519, Validation F1: 0.4320\n",
      "Epoch 54500/100000, Train Loss: 0.2819, Train F1: 0.5568, Validation Loss: 0.4522, Validation F1: 0.4293\n",
      "Epoch 54600/100000, Train Loss: 0.2819, Train F1: 0.5677, Validation Loss: 0.4522, Validation F1: 0.4284\n",
      "Epoch 54700/100000, Train Loss: 0.2806, Train F1: 0.5602, Validation Loss: 0.4526, Validation F1: 0.4295\n",
      "Epoch 54800/100000, Train Loss: 0.2817, Train F1: 0.5652, Validation Loss: 0.4526, Validation F1: 0.4284\n",
      "Epoch 54900/100000, Train Loss: 0.2812, Train F1: 0.5634, Validation Loss: 0.4527, Validation F1: 0.4291\n",
      "Epoch 55000/100000, Train Loss: 0.2814, Train F1: 0.5569, Validation Loss: 0.4527, Validation F1: 0.4302\n",
      "Epoch 55100/100000, Train Loss: 0.2802, Train F1: 0.5642, Validation Loss: 0.4531, Validation F1: 0.4302\n",
      "Epoch 55200/100000, Train Loss: 0.2811, Train F1: 0.5599, Validation Loss: 0.4533, Validation F1: 0.4302\n",
      "Epoch 55300/100000, Train Loss: 0.2800, Train F1: 0.5639, Validation Loss: 0.4536, Validation F1: 0.4308\n",
      "Epoch 55400/100000, Train Loss: 0.2802, Train F1: 0.5637, Validation Loss: 0.4536, Validation F1: 0.4302\n",
      "Epoch 55500/100000, Train Loss: 0.2812, Train F1: 0.5566, Validation Loss: 0.4541, Validation F1: 0.4303\n",
      "Epoch 55600/100000, Train Loss: 0.2787, Train F1: 0.5645, Validation Loss: 0.4544, Validation F1: 0.4301\n",
      "Epoch 55700/100000, Train Loss: 0.2810, Train F1: 0.5568, Validation Loss: 0.4549, Validation F1: 0.4301\n",
      "Epoch 55800/100000, Train Loss: 0.2787, Train F1: 0.5688, Validation Loss: 0.4549, Validation F1: 0.4301\n",
      "Epoch 55900/100000, Train Loss: 0.2793, Train F1: 0.5594, Validation Loss: 0.4548, Validation F1: 0.4303\n",
      "Epoch 56000/100000, Train Loss: 0.2789, Train F1: 0.5680, Validation Loss: 0.4552, Validation F1: 0.4303\n",
      "Epoch 56100/100000, Train Loss: 0.2789, Train F1: 0.5691, Validation Loss: 0.4553, Validation F1: 0.4303\n",
      "Epoch 56200/100000, Train Loss: 0.2798, Train F1: 0.5644, Validation Loss: 0.4554, Validation F1: 0.4297\n",
      "Epoch 56300/100000, Train Loss: 0.2798, Train F1: 0.5648, Validation Loss: 0.4556, Validation F1: 0.4297\n",
      "Epoch 56400/100000, Train Loss: 0.2801, Train F1: 0.5629, Validation Loss: 0.4561, Validation F1: 0.4291\n",
      "Epoch 56500/100000, Train Loss: 0.2794, Train F1: 0.5666, Validation Loss: 0.4560, Validation F1: 0.4297\n",
      "Epoch 56600/100000, Train Loss: 0.2800, Train F1: 0.5683, Validation Loss: 0.4564, Validation F1: 0.4291\n",
      "Epoch 56700/100000, Train Loss: 0.2791, Train F1: 0.5656, Validation Loss: 0.4571, Validation F1: 0.4296\n",
      "Epoch 56800/100000, Train Loss: 0.2787, Train F1: 0.5683, Validation Loss: 0.4565, Validation F1: 0.4311\n",
      "Epoch 56900/100000, Train Loss: 0.2789, Train F1: 0.5643, Validation Loss: 0.4574, Validation F1: 0.4291\n",
      "Epoch 57000/100000, Train Loss: 0.2787, Train F1: 0.5657, Validation Loss: 0.4573, Validation F1: 0.4291\n",
      "Epoch 57100/100000, Train Loss: 0.2789, Train F1: 0.5666, Validation Loss: 0.4576, Validation F1: 0.4291\n",
      "Epoch 57200/100000, Train Loss: 0.2784, Train F1: 0.5621, Validation Loss: 0.4578, Validation F1: 0.4289\n",
      "Epoch 57300/100000, Train Loss: 0.2774, Train F1: 0.5703, Validation Loss: 0.4577, Validation F1: 0.4304\n",
      "Epoch 57400/100000, Train Loss: 0.2790, Train F1: 0.5669, Validation Loss: 0.4586, Validation F1: 0.4283\n",
      "Epoch 57500/100000, Train Loss: 0.2790, Train F1: 0.5596, Validation Loss: 0.4581, Validation F1: 0.4314\n",
      "Epoch 57600/100000, Train Loss: 0.2781, Train F1: 0.5725, Validation Loss: 0.4590, Validation F1: 0.4302\n",
      "Epoch 57700/100000, Train Loss: 0.2774, Train F1: 0.5663, Validation Loss: 0.4586, Validation F1: 0.4314\n",
      "Epoch 57800/100000, Train Loss: 0.2773, Train F1: 0.5725, Validation Loss: 0.4596, Validation F1: 0.4302\n",
      "Epoch 57900/100000, Train Loss: 0.2773, Train F1: 0.5674, Validation Loss: 0.4594, Validation F1: 0.4291\n",
      "Epoch 58000/100000, Train Loss: 0.2780, Train F1: 0.5624, Validation Loss: 0.4592, Validation F1: 0.4298\n",
      "Epoch 58100/100000, Train Loss: 0.2778, Train F1: 0.5678, Validation Loss: 0.4596, Validation F1: 0.4291\n",
      "Epoch 58200/100000, Train Loss: 0.2781, Train F1: 0.5606, Validation Loss: 0.4601, Validation F1: 0.4291\n",
      "Epoch 58300/100000, Train Loss: 0.2773, Train F1: 0.5703, Validation Loss: 0.4602, Validation F1: 0.4298\n",
      "Epoch 58400/100000, Train Loss: 0.2781, Train F1: 0.5636, Validation Loss: 0.4601, Validation F1: 0.4317\n",
      "Epoch 58500/100000, Train Loss: 0.2775, Train F1: 0.5619, Validation Loss: 0.4607, Validation F1: 0.4304\n",
      "Epoch 58600/100000, Train Loss: 0.2762, Train F1: 0.5728, Validation Loss: 0.4609, Validation F1: 0.4304\n",
      "Epoch 58700/100000, Train Loss: 0.2771, Train F1: 0.5687, Validation Loss: 0.4611, Validation F1: 0.4298\n",
      "Epoch 58800/100000, Train Loss: 0.2760, Train F1: 0.5715, Validation Loss: 0.4615, Validation F1: 0.4309\n",
      "Epoch 58900/100000, Train Loss: 0.2754, Train F1: 0.5707, Validation Loss: 0.4618, Validation F1: 0.4309\n",
      "Epoch 59000/100000, Train Loss: 0.2760, Train F1: 0.5674, Validation Loss: 0.4618, Validation F1: 0.4304\n",
      "Epoch 59100/100000, Train Loss: 0.2760, Train F1: 0.5723, Validation Loss: 0.4618, Validation F1: 0.4304\n",
      "Epoch 59200/100000, Train Loss: 0.2755, Train F1: 0.5764, Validation Loss: 0.4622, Validation F1: 0.4304\n",
      "Epoch 59300/100000, Train Loss: 0.2757, Train F1: 0.5731, Validation Loss: 0.4622, Validation F1: 0.4316\n",
      "Epoch 59400/100000, Train Loss: 0.2770, Train F1: 0.5716, Validation Loss: 0.4631, Validation F1: 0.4303\n",
      "Epoch 59500/100000, Train Loss: 0.2760, Train F1: 0.5727, Validation Loss: 0.4632, Validation F1: 0.4309\n",
      "Epoch 59600/100000, Train Loss: 0.2754, Train F1: 0.5704, Validation Loss: 0.4630, Validation F1: 0.4299\n",
      "Epoch 59700/100000, Train Loss: 0.2744, Train F1: 0.5736, Validation Loss: 0.4630, Validation F1: 0.4311\n",
      "Epoch 59800/100000, Train Loss: 0.2759, Train F1: 0.5755, Validation Loss: 0.4635, Validation F1: 0.4304\n",
      "Epoch 59900/100000, Train Loss: 0.2751, Train F1: 0.5657, Validation Loss: 0.4637, Validation F1: 0.4299\n",
      "Epoch 60000/100000, Train Loss: 0.2735, Train F1: 0.5668, Validation Loss: 0.4639, Validation F1: 0.4311\n",
      "Epoch 60100/100000, Train Loss: 0.2749, Train F1: 0.5755, Validation Loss: 0.4641, Validation F1: 0.4316\n",
      "Epoch 60200/100000, Train Loss: 0.2750, Train F1: 0.5763, Validation Loss: 0.4644, Validation F1: 0.4309\n",
      "Epoch 60300/100000, Train Loss: 0.2744, Train F1: 0.5776, Validation Loss: 0.4647, Validation F1: 0.4314\n",
      "Epoch 60400/100000, Train Loss: 0.2735, Train F1: 0.5756, Validation Loss: 0.4648, Validation F1: 0.4304\n",
      "Epoch 60500/100000, Train Loss: 0.2733, Train F1: 0.5741, Validation Loss: 0.4652, Validation F1: 0.4302\n",
      "Epoch 60600/100000, Train Loss: 0.2739, Train F1: 0.5758, Validation Loss: 0.4657, Validation F1: 0.4302\n",
      "Epoch 60700/100000, Train Loss: 0.2752, Train F1: 0.5782, Validation Loss: 0.4654, Validation F1: 0.4303\n",
      "Epoch 60800/100000, Train Loss: 0.2748, Train F1: 0.5750, Validation Loss: 0.4656, Validation F1: 0.4303\n",
      "Epoch 60900/100000, Train Loss: 0.2728, Train F1: 0.5758, Validation Loss: 0.4660, Validation F1: 0.4314\n",
      "Epoch 61000/100000, Train Loss: 0.2737, Train F1: 0.5752, Validation Loss: 0.4661, Validation F1: 0.4309\n",
      "Epoch 61100/100000, Train Loss: 0.2756, Train F1: 0.5699, Validation Loss: 0.4664, Validation F1: 0.4314\n",
      "Epoch 61200/100000, Train Loss: 0.2740, Train F1: 0.5798, Validation Loss: 0.4666, Validation F1: 0.4314\n",
      "Epoch 61300/100000, Train Loss: 0.2718, Train F1: 0.5754, Validation Loss: 0.4669, Validation F1: 0.4313\n",
      "Epoch 61400/100000, Train Loss: 0.2723, Train F1: 0.5798, Validation Loss: 0.4670, Validation F1: 0.4327\n",
      "Epoch 61500/100000, Train Loss: 0.2719, Train F1: 0.5777, Validation Loss: 0.4674, Validation F1: 0.4313\n",
      "Epoch 61600/100000, Train Loss: 0.2722, Train F1: 0.5772, Validation Loss: 0.4673, Validation F1: 0.4334\n",
      "Epoch 61700/100000, Train Loss: 0.2729, Train F1: 0.5802, Validation Loss: 0.4680, Validation F1: 0.4301\n",
      "Epoch 61800/100000, Train Loss: 0.2718, Train F1: 0.5788, Validation Loss: 0.4683, Validation F1: 0.4330\n",
      "Epoch 61900/100000, Train Loss: 0.2733, Train F1: 0.5783, Validation Loss: 0.4682, Validation F1: 0.4331\n",
      "Epoch 62000/100000, Train Loss: 0.2729, Train F1: 0.5735, Validation Loss: 0.4685, Validation F1: 0.4344\n",
      "Epoch 62100/100000, Train Loss: 0.2738, Train F1: 0.5797, Validation Loss: 0.4687, Validation F1: 0.4344\n",
      "Epoch 62200/100000, Train Loss: 0.2733, Train F1: 0.5754, Validation Loss: 0.4693, Validation F1: 0.4306\n",
      "Epoch 62300/100000, Train Loss: 0.2723, Train F1: 0.5810, Validation Loss: 0.4690, Validation F1: 0.4331\n",
      "Epoch 62400/100000, Train Loss: 0.2714, Train F1: 0.5789, Validation Loss: 0.4692, Validation F1: 0.4317\n",
      "Epoch 62500/100000, Train Loss: 0.2716, Train F1: 0.5771, Validation Loss: 0.4696, Validation F1: 0.4344\n",
      "Epoch 62600/100000, Train Loss: 0.2735, Train F1: 0.5706, Validation Loss: 0.4699, Validation F1: 0.4344\n",
      "Epoch 62700/100000, Train Loss: 0.2712, Train F1: 0.5823, Validation Loss: 0.4703, Validation F1: 0.4349\n",
      "Epoch 62800/100000, Train Loss: 0.2713, Train F1: 0.5807, Validation Loss: 0.4706, Validation F1: 0.4349\n",
      "Epoch 62900/100000, Train Loss: 0.2724, Train F1: 0.5788, Validation Loss: 0.4706, Validation F1: 0.4317\n",
      "Epoch 63000/100000, Train Loss: 0.2714, Train F1: 0.5814, Validation Loss: 0.4709, Validation F1: 0.4375\n",
      "Epoch 63100/100000, Train Loss: 0.2725, Train F1: 0.5806, Validation Loss: 0.4709, Validation F1: 0.4291\n",
      "Epoch 63200/100000, Train Loss: 0.2721, Train F1: 0.5802, Validation Loss: 0.4714, Validation F1: 0.4368\n",
      "Epoch 63300/100000, Train Loss: 0.2695, Train F1: 0.5825, Validation Loss: 0.4715, Validation F1: 0.4296\n",
      "Epoch 63400/100000, Train Loss: 0.2714, Train F1: 0.5841, Validation Loss: 0.4719, Validation F1: 0.4368\n",
      "Epoch 63500/100000, Train Loss: 0.2710, Train F1: 0.5763, Validation Loss: 0.4720, Validation F1: 0.4349\n",
      "Epoch 63600/100000, Train Loss: 0.2716, Train F1: 0.5817, Validation Loss: 0.4726, Validation F1: 0.4368\n",
      "Epoch 63700/100000, Train Loss: 0.2706, Train F1: 0.5776, Validation Loss: 0.4729, Validation F1: 0.4394\n",
      "Epoch 63800/100000, Train Loss: 0.2705, Train F1: 0.5835, Validation Loss: 0.4728, Validation F1: 0.4368\n",
      "Epoch 63900/100000, Train Loss: 0.2704, Train F1: 0.5844, Validation Loss: 0.4732, Validation F1: 0.4323\n",
      "Epoch 64000/100000, Train Loss: 0.2707, Train F1: 0.5816, Validation Loss: 0.4735, Validation F1: 0.4342\n",
      "Epoch 64100/100000, Train Loss: 0.2691, Train F1: 0.5837, Validation Loss: 0.4731, Validation F1: 0.4317\n",
      "Epoch 64200/100000, Train Loss: 0.2700, Train F1: 0.5774, Validation Loss: 0.4738, Validation F1: 0.4370\n",
      "Epoch 64300/100000, Train Loss: 0.2700, Train F1: 0.5799, Validation Loss: 0.4742, Validation F1: 0.4350\n",
      "Epoch 64400/100000, Train Loss: 0.2684, Train F1: 0.5877, Validation Loss: 0.4744, Validation F1: 0.4363\n",
      "Epoch 64500/100000, Train Loss: 0.2699, Train F1: 0.5839, Validation Loss: 0.4745, Validation F1: 0.4344\n",
      "Epoch 64600/100000, Train Loss: 0.2695, Train F1: 0.5903, Validation Loss: 0.4747, Validation F1: 0.4370\n",
      "Epoch 64700/100000, Train Loss: 0.2710, Train F1: 0.5787, Validation Loss: 0.4751, Validation F1: 0.4370\n",
      "Epoch 64800/100000, Train Loss: 0.2695, Train F1: 0.5858, Validation Loss: 0.4749, Validation F1: 0.4370\n",
      "Epoch 64900/100000, Train Loss: 0.2701, Train F1: 0.5824, Validation Loss: 0.4759, Validation F1: 0.4357\n",
      "Epoch 65000/100000, Train Loss: 0.2691, Train F1: 0.5861, Validation Loss: 0.4754, Validation F1: 0.4344\n",
      "Epoch 65100/100000, Train Loss: 0.2702, Train F1: 0.5824, Validation Loss: 0.4760, Validation F1: 0.4344\n",
      "Epoch 65200/100000, Train Loss: 0.2680, Train F1: 0.5895, Validation Loss: 0.4763, Validation F1: 0.4356\n",
      "Epoch 65300/100000, Train Loss: 0.2685, Train F1: 0.5911, Validation Loss: 0.4766, Validation F1: 0.4357\n",
      "Epoch 65400/100000, Train Loss: 0.2686, Train F1: 0.5828, Validation Loss: 0.4767, Validation F1: 0.4356\n",
      "Epoch 65500/100000, Train Loss: 0.2672, Train F1: 0.5890, Validation Loss: 0.4771, Validation F1: 0.4345\n",
      "Epoch 65600/100000, Train Loss: 0.2680, Train F1: 0.5895, Validation Loss: 0.4773, Validation F1: 0.4328\n",
      "Epoch 65700/100000, Train Loss: 0.2683, Train F1: 0.5822, Validation Loss: 0.4772, Validation F1: 0.4346\n",
      "Epoch 65800/100000, Train Loss: 0.2687, Train F1: 0.5858, Validation Loss: 0.4775, Validation F1: 0.4335\n",
      "Epoch 65900/100000, Train Loss: 0.2686, Train F1: 0.5852, Validation Loss: 0.4778, Validation F1: 0.4346\n",
      "Epoch 66000/100000, Train Loss: 0.2684, Train F1: 0.5863, Validation Loss: 0.4780, Validation F1: 0.4337\n",
      "Epoch 66100/100000, Train Loss: 0.2686, Train F1: 0.5869, Validation Loss: 0.4782, Validation F1: 0.4348\n",
      "Epoch 66200/100000, Train Loss: 0.2667, Train F1: 0.5914, Validation Loss: 0.4783, Validation F1: 0.4357\n",
      "Epoch 66300/100000, Train Loss: 0.2660, Train F1: 0.5820, Validation Loss: 0.4789, Validation F1: 0.4337\n",
      "Epoch 66400/100000, Train Loss: 0.2682, Train F1: 0.5862, Validation Loss: 0.4791, Validation F1: 0.4321\n",
      "Epoch 66500/100000, Train Loss: 0.2675, Train F1: 0.5905, Validation Loss: 0.4795, Validation F1: 0.4321\n",
      "Epoch 66600/100000, Train Loss: 0.2673, Train F1: 0.5879, Validation Loss: 0.4796, Validation F1: 0.4321\n",
      "Epoch 66700/100000, Train Loss: 0.2670, Train F1: 0.5883, Validation Loss: 0.4800, Validation F1: 0.4304\n",
      "Epoch 66800/100000, Train Loss: 0.2683, Train F1: 0.5837, Validation Loss: 0.4801, Validation F1: 0.4321\n",
      "Epoch 66900/100000, Train Loss: 0.2666, Train F1: 0.5897, Validation Loss: 0.4803, Validation F1: 0.4321\n",
      "Epoch 67000/100000, Train Loss: 0.2674, Train F1: 0.5864, Validation Loss: 0.4808, Validation F1: 0.4333\n",
      "Epoch 67100/100000, Train Loss: 0.2664, Train F1: 0.5861, Validation Loss: 0.4812, Validation F1: 0.4313\n",
      "Epoch 67200/100000, Train Loss: 0.2655, Train F1: 0.5845, Validation Loss: 0.4815, Validation F1: 0.4339\n",
      "Epoch 67300/100000, Train Loss: 0.2678, Train F1: 0.5872, Validation Loss: 0.4815, Validation F1: 0.4332\n",
      "Epoch 67400/100000, Train Loss: 0.2670, Train F1: 0.5893, Validation Loss: 0.4816, Validation F1: 0.4327\n",
      "Epoch 67500/100000, Train Loss: 0.2665, Train F1: 0.5889, Validation Loss: 0.4816, Validation F1: 0.4340\n",
      "Epoch 67600/100000, Train Loss: 0.2657, Train F1: 0.5886, Validation Loss: 0.4826, Validation F1: 0.4339\n",
      "Epoch 67700/100000, Train Loss: 0.2658, Train F1: 0.5886, Validation Loss: 0.4825, Validation F1: 0.4339\n",
      "Epoch 67800/100000, Train Loss: 0.2670, Train F1: 0.5920, Validation Loss: 0.4828, Validation F1: 0.4332\n",
      "Epoch 67900/100000, Train Loss: 0.2654, Train F1: 0.5931, Validation Loss: 0.4829, Validation F1: 0.4326\n",
      "Epoch 68000/100000, Train Loss: 0.2673, Train F1: 0.5902, Validation Loss: 0.4831, Validation F1: 0.4350\n",
      "Epoch 68100/100000, Train Loss: 0.2650, Train F1: 0.5834, Validation Loss: 0.4831, Validation F1: 0.4345\n",
      "Epoch 68200/100000, Train Loss: 0.2648, Train F1: 0.5884, Validation Loss: 0.4837, Validation F1: 0.4332\n",
      "Epoch 68300/100000, Train Loss: 0.2642, Train F1: 0.5909, Validation Loss: 0.4840, Validation F1: 0.4352\n",
      "Epoch 68400/100000, Train Loss: 0.2684, Train F1: 0.5851, Validation Loss: 0.4841, Validation F1: 0.4364\n",
      "Epoch 68500/100000, Train Loss: 0.2641, Train F1: 0.5969, Validation Loss: 0.4846, Validation F1: 0.4352\n",
      "Epoch 68600/100000, Train Loss: 0.2653, Train F1: 0.5907, Validation Loss: 0.4847, Validation F1: 0.4352\n",
      "Epoch 68700/100000, Train Loss: 0.2646, Train F1: 0.5934, Validation Loss: 0.4853, Validation F1: 0.4352\n",
      "Epoch 68800/100000, Train Loss: 0.2649, Train F1: 0.5935, Validation Loss: 0.4848, Validation F1: 0.4364\n",
      "Epoch 68900/100000, Train Loss: 0.2648, Train F1: 0.5958, Validation Loss: 0.4852, Validation F1: 0.4364\n",
      "Epoch 69000/100000, Train Loss: 0.2645, Train F1: 0.5946, Validation Loss: 0.4859, Validation F1: 0.4345\n",
      "Epoch 69100/100000, Train Loss: 0.2629, Train F1: 0.5949, Validation Loss: 0.4864, Validation F1: 0.4296\n",
      "Epoch 69200/100000, Train Loss: 0.2646, Train F1: 0.5888, Validation Loss: 0.4859, Validation F1: 0.4357\n",
      "Epoch 69300/100000, Train Loss: 0.2635, Train F1: 0.5922, Validation Loss: 0.4862, Validation F1: 0.4338\n",
      "Epoch 69400/100000, Train Loss: 0.2632, Train F1: 0.6011, Validation Loss: 0.4866, Validation F1: 0.4345\n",
      "Epoch 69500/100000, Train Loss: 0.2646, Train F1: 0.5926, Validation Loss: 0.4873, Validation F1: 0.4371\n",
      "Epoch 69600/100000, Train Loss: 0.2633, Train F1: 0.5952, Validation Loss: 0.4873, Validation F1: 0.4319\n",
      "Epoch 69700/100000, Train Loss: 0.2631, Train F1: 0.5961, Validation Loss: 0.4870, Validation F1: 0.4344\n",
      "Epoch 69800/100000, Train Loss: 0.2630, Train F1: 0.5944, Validation Loss: 0.4876, Validation F1: 0.4364\n",
      "Epoch 69900/100000, Train Loss: 0.2643, Train F1: 0.5933, Validation Loss: 0.4879, Validation F1: 0.4344\n",
      "Epoch 70000/100000, Train Loss: 0.2641, Train F1: 0.5873, Validation Loss: 0.4879, Validation F1: 0.4350\n",
      "Epoch 70100/100000, Train Loss: 0.2652, Train F1: 0.5911, Validation Loss: 0.4881, Validation F1: 0.4318\n",
      "Epoch 70200/100000, Train Loss: 0.2631, Train F1: 0.5981, Validation Loss: 0.4892, Validation F1: 0.4357\n",
      "Epoch 70300/100000, Train Loss: 0.2627, Train F1: 0.5922, Validation Loss: 0.4892, Validation F1: 0.4345\n",
      "Epoch 70400/100000, Train Loss: 0.2639, Train F1: 0.5927, Validation Loss: 0.4891, Validation F1: 0.4331\n",
      "Epoch 70500/100000, Train Loss: 0.2629, Train F1: 0.5990, Validation Loss: 0.4896, Validation F1: 0.4350\n",
      "Epoch 70600/100000, Train Loss: 0.2636, Train F1: 0.5929, Validation Loss: 0.4897, Validation F1: 0.4343\n",
      "Epoch 70700/100000, Train Loss: 0.2623, Train F1: 0.5991, Validation Loss: 0.4900, Validation F1: 0.4341\n",
      "Epoch 70800/100000, Train Loss: 0.2631, Train F1: 0.5939, Validation Loss: 0.4904, Validation F1: 0.4341\n",
      "Epoch 70900/100000, Train Loss: 0.2633, Train F1: 0.5986, Validation Loss: 0.4910, Validation F1: 0.4305\n",
      "Epoch 71000/100000, Train Loss: 0.2608, Train F1: 0.6015, Validation Loss: 0.4912, Validation F1: 0.4330\n",
      "Epoch 71100/100000, Train Loss: 0.2614, Train F1: 0.6008, Validation Loss: 0.4911, Validation F1: 0.4341\n",
      "Epoch 71200/100000, Train Loss: 0.2627, Train F1: 0.5965, Validation Loss: 0.4912, Validation F1: 0.4336\n",
      "Epoch 71300/100000, Train Loss: 0.2632, Train F1: 0.5995, Validation Loss: 0.4917, Validation F1: 0.4304\n",
      "Epoch 71400/100000, Train Loss: 0.2617, Train F1: 0.5970, Validation Loss: 0.4920, Validation F1: 0.4304\n",
      "Epoch 71500/100000, Train Loss: 0.2611, Train F1: 0.5973, Validation Loss: 0.4924, Validation F1: 0.4330\n",
      "Epoch 71600/100000, Train Loss: 0.2620, Train F1: 0.6039, Validation Loss: 0.4924, Validation F1: 0.4355\n",
      "Epoch 71700/100000, Train Loss: 0.2614, Train F1: 0.5934, Validation Loss: 0.4929, Validation F1: 0.4304\n",
      "Epoch 71800/100000, Train Loss: 0.2602, Train F1: 0.6062, Validation Loss: 0.4928, Validation F1: 0.4285\n",
      "Epoch 71900/100000, Train Loss: 0.2607, Train F1: 0.5970, Validation Loss: 0.4929, Validation F1: 0.4279\n",
      "Epoch 72000/100000, Train Loss: 0.2614, Train F1: 0.5964, Validation Loss: 0.4935, Validation F1: 0.4324\n",
      "Epoch 72100/100000, Train Loss: 0.2606, Train F1: 0.5999, Validation Loss: 0.4937, Validation F1: 0.4349\n",
      "Epoch 72200/100000, Train Loss: 0.2610, Train F1: 0.5985, Validation Loss: 0.4934, Validation F1: 0.4279\n",
      "Epoch 72300/100000, Train Loss: 0.2608, Train F1: 0.6021, Validation Loss: 0.4941, Validation F1: 0.4299\n",
      "Epoch 72400/100000, Train Loss: 0.2607, Train F1: 0.6017, Validation Loss: 0.4949, Validation F1: 0.4335\n",
      "Epoch 72500/100000, Train Loss: 0.2609, Train F1: 0.6006, Validation Loss: 0.4947, Validation F1: 0.4319\n",
      "Epoch 72600/100000, Train Loss: 0.2606, Train F1: 0.6029, Validation Loss: 0.4950, Validation F1: 0.4293\n",
      "Epoch 72700/100000, Train Loss: 0.2617, Train F1: 0.5968, Validation Loss: 0.4956, Validation F1: 0.4324\n",
      "Epoch 72800/100000, Train Loss: 0.2589, Train F1: 0.6031, Validation Loss: 0.4955, Validation F1: 0.4293\n",
      "Epoch 72900/100000, Train Loss: 0.2581, Train F1: 0.6088, Validation Loss: 0.4959, Validation F1: 0.4330\n",
      "Epoch 73000/100000, Train Loss: 0.2602, Train F1: 0.5975, Validation Loss: 0.4960, Validation F1: 0.4293\n",
      "Epoch 73100/100000, Train Loss: 0.2596, Train F1: 0.6030, Validation Loss: 0.4967, Validation F1: 0.4335\n",
      "Epoch 73200/100000, Train Loss: 0.2614, Train F1: 0.5980, Validation Loss: 0.4967, Validation F1: 0.4330\n",
      "Epoch 73300/100000, Train Loss: 0.2594, Train F1: 0.6047, Validation Loss: 0.4968, Validation F1: 0.4293\n",
      "Epoch 73400/100000, Train Loss: 0.2582, Train F1: 0.6101, Validation Loss: 0.4969, Validation F1: 0.4268\n",
      "Epoch 73500/100000, Train Loss: 0.2592, Train F1: 0.6048, Validation Loss: 0.4974, Validation F1: 0.4273\n",
      "Epoch 73600/100000, Train Loss: 0.2584, Train F1: 0.6025, Validation Loss: 0.4979, Validation F1: 0.4318\n",
      "Epoch 73700/100000, Train Loss: 0.2597, Train F1: 0.6008, Validation Loss: 0.4983, Validation F1: 0.4298\n",
      "Epoch 73800/100000, Train Loss: 0.2600, Train F1: 0.6027, Validation Loss: 0.4981, Validation F1: 0.4273\n",
      "Epoch 73900/100000, Train Loss: 0.2593, Train F1: 0.6025, Validation Loss: 0.4984, Validation F1: 0.4267\n",
      "Epoch 74000/100000, Train Loss: 0.2594, Train F1: 0.5975, Validation Loss: 0.4990, Validation F1: 0.4298\n",
      "Epoch 74100/100000, Train Loss: 0.2588, Train F1: 0.6064, Validation Loss: 0.4993, Validation F1: 0.4272\n",
      "Epoch 74200/100000, Train Loss: 0.2556, Train F1: 0.6124, Validation Loss: 0.4992, Validation F1: 0.4267\n",
      "Epoch 74300/100000, Train Loss: 0.2587, Train F1: 0.6035, Validation Loss: 0.4998, Validation F1: 0.4316\n",
      "Epoch 74400/100000, Train Loss: 0.2580, Train F1: 0.6051, Validation Loss: 0.5003, Validation F1: 0.4297\n",
      "Epoch 74500/100000, Train Loss: 0.2583, Train F1: 0.6036, Validation Loss: 0.5003, Validation F1: 0.4292\n",
      "Epoch 74600/100000, Train Loss: 0.2581, Train F1: 0.6082, Validation Loss: 0.5004, Validation F1: 0.4280\n",
      "Epoch 74700/100000, Train Loss: 0.2569, Train F1: 0.6105, Validation Loss: 0.5008, Validation F1: 0.4277\n",
      "Epoch 74800/100000, Train Loss: 0.2598, Train F1: 0.6066, Validation Loss: 0.5012, Validation F1: 0.4290\n",
      "Epoch 74900/100000, Train Loss: 0.2560, Train F1: 0.6103, Validation Loss: 0.5014, Validation F1: 0.4290\n",
      "Epoch 75000/100000, Train Loss: 0.2574, Train F1: 0.6001, Validation Loss: 0.5019, Validation F1: 0.4296\n",
      "Epoch 75100/100000, Train Loss: 0.2578, Train F1: 0.6079, Validation Loss: 0.5019, Validation F1: 0.4259\n",
      "Epoch 75200/100000, Train Loss: 0.2567, Train F1: 0.6071, Validation Loss: 0.5028, Validation F1: 0.4295\n",
      "Epoch 75300/100000, Train Loss: 0.2576, Train F1: 0.6055, Validation Loss: 0.5022, Validation F1: 0.4284\n",
      "Epoch 75400/100000, Train Loss: 0.2562, Train F1: 0.6015, Validation Loss: 0.5033, Validation F1: 0.4289\n",
      "Epoch 75500/100000, Train Loss: 0.2567, Train F1: 0.6130, Validation Loss: 0.5028, Validation F1: 0.4259\n",
      "Epoch 75600/100000, Train Loss: 0.2567, Train F1: 0.6088, Validation Loss: 0.5037, Validation F1: 0.4252\n",
      "Epoch 75700/100000, Train Loss: 0.2558, Train F1: 0.6154, Validation Loss: 0.5037, Validation F1: 0.4264\n",
      "Epoch 75800/100000, Train Loss: 0.2562, Train F1: 0.6036, Validation Loss: 0.5039, Validation F1: 0.4264\n",
      "Epoch 75900/100000, Train Loss: 0.2565, Train F1: 0.6153, Validation Loss: 0.5042, Validation F1: 0.4251\n",
      "Epoch 76000/100000, Train Loss: 0.2563, Train F1: 0.6137, Validation Loss: 0.5047, Validation F1: 0.4238\n",
      "Epoch 76100/100000, Train Loss: 0.2561, Train F1: 0.6053, Validation Loss: 0.5044, Validation F1: 0.4245\n",
      "Epoch 76200/100000, Train Loss: 0.2554, Train F1: 0.6134, Validation Loss: 0.5053, Validation F1: 0.4232\n",
      "Epoch 76300/100000, Train Loss: 0.2556, Train F1: 0.6159, Validation Loss: 0.5054, Validation F1: 0.4243\n",
      "Epoch 76400/100000, Train Loss: 0.2553, Train F1: 0.6126, Validation Loss: 0.5058, Validation F1: 0.4276\n",
      "Epoch 76500/100000, Train Loss: 0.2555, Train F1: 0.6123, Validation Loss: 0.5062, Validation F1: 0.4261\n",
      "Epoch 76600/100000, Train Loss: 0.2550, Train F1: 0.6117, Validation Loss: 0.5060, Validation F1: 0.4258\n",
      "Epoch 76700/100000, Train Loss: 0.2554, Train F1: 0.6104, Validation Loss: 0.5068, Validation F1: 0.4225\n",
      "Epoch 76800/100000, Train Loss: 0.2552, Train F1: 0.6106, Validation Loss: 0.5071, Validation F1: 0.4264\n",
      "Epoch 76900/100000, Train Loss: 0.2557, Train F1: 0.6015, Validation Loss: 0.5072, Validation F1: 0.4220\n",
      "Epoch 77000/100000, Train Loss: 0.2564, Train F1: 0.6031, Validation Loss: 0.5069, Validation F1: 0.4227\n",
      "Epoch 77100/100000, Train Loss: 0.2557, Train F1: 0.6094, Validation Loss: 0.5083, Validation F1: 0.4238\n",
      "Epoch 77200/100000, Train Loss: 0.2547, Train F1: 0.6171, Validation Loss: 0.5083, Validation F1: 0.4238\n",
      "Epoch 77300/100000, Train Loss: 0.2557, Train F1: 0.6081, Validation Loss: 0.5083, Validation F1: 0.4219\n",
      "Epoch 77400/100000, Train Loss: 0.2548, Train F1: 0.6151, Validation Loss: 0.5086, Validation F1: 0.4219\n",
      "Epoch 77500/100000, Train Loss: 0.2565, Train F1: 0.6117, Validation Loss: 0.5090, Validation F1: 0.4209\n",
      "Epoch 77600/100000, Train Loss: 0.2554, Train F1: 0.6125, Validation Loss: 0.5090, Validation F1: 0.4215\n",
      "Epoch 77700/100000, Train Loss: 0.2556, Train F1: 0.6128, Validation Loss: 0.5095, Validation F1: 0.4207\n",
      "Epoch 77800/100000, Train Loss: 0.2538, Train F1: 0.6108, Validation Loss: 0.5094, Validation F1: 0.4248\n",
      "Epoch 77900/100000, Train Loss: 0.2548, Train F1: 0.6154, Validation Loss: 0.5099, Validation F1: 0.4213\n",
      "Epoch 78000/100000, Train Loss: 0.2532, Train F1: 0.6175, Validation Loss: 0.5107, Validation F1: 0.4207\n",
      "Epoch 78100/100000, Train Loss: 0.2528, Train F1: 0.6156, Validation Loss: 0.5107, Validation F1: 0.4240\n",
      "Epoch 78200/100000, Train Loss: 0.2535, Train F1: 0.6173, Validation Loss: 0.5108, Validation F1: 0.4225\n",
      "Epoch 78300/100000, Train Loss: 0.2538, Train F1: 0.6144, Validation Loss: 0.5115, Validation F1: 0.4221\n",
      "Epoch 78400/100000, Train Loss: 0.2531, Train F1: 0.6095, Validation Loss: 0.5116, Validation F1: 0.4225\n",
      "Epoch 78500/100000, Train Loss: 0.2534, Train F1: 0.6171, Validation Loss: 0.5119, Validation F1: 0.4213\n",
      "Epoch 78600/100000, Train Loss: 0.2549, Train F1: 0.6096, Validation Loss: 0.5119, Validation F1: 0.4237\n",
      "Epoch 78700/100000, Train Loss: 0.2524, Train F1: 0.6140, Validation Loss: 0.5127, Validation F1: 0.4219\n",
      "Epoch 78800/100000, Train Loss: 0.2527, Train F1: 0.6151, Validation Loss: 0.5126, Validation F1: 0.4243\n",
      "Epoch 78900/100000, Train Loss: 0.2524, Train F1: 0.6155, Validation Loss: 0.5129, Validation F1: 0.4231\n",
      "Epoch 79000/100000, Train Loss: 0.2533, Train F1: 0.6190, Validation Loss: 0.5127, Validation F1: 0.4244\n",
      "Epoch 79100/100000, Train Loss: 0.2523, Train F1: 0.6132, Validation Loss: 0.5133, Validation F1: 0.4249\n",
      "Epoch 79200/100000, Train Loss: 0.2537, Train F1: 0.6074, Validation Loss: 0.5145, Validation F1: 0.4245\n",
      "Epoch 79300/100000, Train Loss: 0.2533, Train F1: 0.6160, Validation Loss: 0.5141, Validation F1: 0.4236\n",
      "Epoch 79400/100000, Train Loss: 0.2525, Train F1: 0.6114, Validation Loss: 0.5146, Validation F1: 0.4225\n",
      "Epoch 79500/100000, Train Loss: 0.2517, Train F1: 0.6138, Validation Loss: 0.5146, Validation F1: 0.4236\n",
      "Epoch 79600/100000, Train Loss: 0.2525, Train F1: 0.6190, Validation Loss: 0.5154, Validation F1: 0.4243\n",
      "Epoch 79700/100000, Train Loss: 0.2516, Train F1: 0.6165, Validation Loss: 0.5153, Validation F1: 0.4236\n",
      "Epoch 79800/100000, Train Loss: 0.2525, Train F1: 0.6154, Validation Loss: 0.5152, Validation F1: 0.4249\n",
      "Epoch 79900/100000, Train Loss: 0.2512, Train F1: 0.6143, Validation Loss: 0.5161, Validation F1: 0.4231\n",
      "Epoch 80000/100000, Train Loss: 0.2522, Train F1: 0.6160, Validation Loss: 0.5158, Validation F1: 0.4250\n",
      "Epoch 80100/100000, Train Loss: 0.2514, Train F1: 0.6157, Validation Loss: 0.5165, Validation F1: 0.4244\n",
      "Epoch 80200/100000, Train Loss: 0.2517, Train F1: 0.6197, Validation Loss: 0.5165, Validation F1: 0.4256\n",
      "Epoch 80300/100000, Train Loss: 0.2499, Train F1: 0.6217, Validation Loss: 0.5176, Validation F1: 0.4244\n",
      "Epoch 80400/100000, Train Loss: 0.2519, Train F1: 0.6162, Validation Loss: 0.5178, Validation F1: 0.4244\n",
      "Epoch 80500/100000, Train Loss: 0.2517, Train F1: 0.6155, Validation Loss: 0.5174, Validation F1: 0.4250\n",
      "Epoch 80600/100000, Train Loss: 0.2525, Train F1: 0.6196, Validation Loss: 0.5178, Validation F1: 0.4238\n",
      "Epoch 80700/100000, Train Loss: 0.2500, Train F1: 0.6248, Validation Loss: 0.5183, Validation F1: 0.4238\n",
      "Epoch 80800/100000, Train Loss: 0.2526, Train F1: 0.6207, Validation Loss: 0.5183, Validation F1: 0.4256\n",
      "Epoch 80900/100000, Train Loss: 0.2506, Train F1: 0.6287, Validation Loss: 0.5189, Validation F1: 0.4238\n",
      "Epoch 81000/100000, Train Loss: 0.2505, Train F1: 0.6139, Validation Loss: 0.5191, Validation F1: 0.4250\n",
      "Epoch 81100/100000, Train Loss: 0.2517, Train F1: 0.6155, Validation Loss: 0.5192, Validation F1: 0.4256\n",
      "Epoch 81200/100000, Train Loss: 0.2517, Train F1: 0.6201, Validation Loss: 0.5196, Validation F1: 0.4256\n",
      "Epoch 81300/100000, Train Loss: 0.2513, Train F1: 0.6167, Validation Loss: 0.5203, Validation F1: 0.4233\n",
      "Epoch 81400/100000, Train Loss: 0.2501, Train F1: 0.6175, Validation Loss: 0.5204, Validation F1: 0.4233\n",
      "Epoch 81500/100000, Train Loss: 0.2506, Train F1: 0.6165, Validation Loss: 0.5211, Validation F1: 0.4238\n",
      "Epoch 81600/100000, Train Loss: 0.2488, Train F1: 0.6217, Validation Loss: 0.5210, Validation F1: 0.4245\n",
      "Epoch 81700/100000, Train Loss: 0.2492, Train F1: 0.6190, Validation Loss: 0.5217, Validation F1: 0.4233\n",
      "Epoch 81800/100000, Train Loss: 0.2486, Train F1: 0.6213, Validation Loss: 0.5220, Validation F1: 0.4233\n",
      "Epoch 81900/100000, Train Loss: 0.2510, Train F1: 0.6151, Validation Loss: 0.5219, Validation F1: 0.4233\n",
      "Epoch 82000/100000, Train Loss: 0.2488, Train F1: 0.6237, Validation Loss: 0.5222, Validation F1: 0.4245\n",
      "Epoch 82100/100000, Train Loss: 0.2488, Train F1: 0.6248, Validation Loss: 0.5225, Validation F1: 0.4256\n",
      "Epoch 82200/100000, Train Loss: 0.2500, Train F1: 0.6211, Validation Loss: 0.5224, Validation F1: 0.4256\n",
      "Epoch 82300/100000, Train Loss: 0.2488, Train F1: 0.6156, Validation Loss: 0.5234, Validation F1: 0.4207\n",
      "Epoch 82400/100000, Train Loss: 0.2490, Train F1: 0.6197, Validation Loss: 0.5232, Validation F1: 0.4282\n",
      "Epoch 82500/100000, Train Loss: 0.2485, Train F1: 0.6170, Validation Loss: 0.5248, Validation F1: 0.4278\n",
      "Epoch 82600/100000, Train Loss: 0.2490, Train F1: 0.6163, Validation Loss: 0.5240, Validation F1: 0.4256\n",
      "Epoch 82700/100000, Train Loss: 0.2495, Train F1: 0.6178, Validation Loss: 0.5247, Validation F1: 0.4233\n",
      "Epoch 82800/100000, Train Loss: 0.2492, Train F1: 0.6176, Validation Loss: 0.5259, Validation F1: 0.4246\n",
      "Epoch 82900/100000, Train Loss: 0.2496, Train F1: 0.6191, Validation Loss: 0.5247, Validation F1: 0.4268\n",
      "Epoch 83000/100000, Train Loss: 0.2489, Train F1: 0.6225, Validation Loss: 0.5255, Validation F1: 0.4221\n",
      "Epoch 83100/100000, Train Loss: 0.2470, Train F1: 0.6269, Validation Loss: 0.5253, Validation F1: 0.4249\n",
      "Epoch 83200/100000, Train Loss: 0.2497, Train F1: 0.6203, Validation Loss: 0.5263, Validation F1: 0.4232\n",
      "Epoch 83300/100000, Train Loss: 0.2474, Train F1: 0.6283, Validation Loss: 0.5266, Validation F1: 0.4226\n",
      "Epoch 83400/100000, Train Loss: 0.2478, Train F1: 0.6246, Validation Loss: 0.5262, Validation F1: 0.4280\n",
      "Epoch 83500/100000, Train Loss: 0.2484, Train F1: 0.6309, Validation Loss: 0.5277, Validation F1: 0.4241\n",
      "Epoch 83600/100000, Train Loss: 0.2487, Train F1: 0.6229, Validation Loss: 0.5280, Validation F1: 0.4241\n",
      "Epoch 83700/100000, Train Loss: 0.2472, Train F1: 0.6197, Validation Loss: 0.5274, Validation F1: 0.4275\n",
      "Epoch 83800/100000, Train Loss: 0.2471, Train F1: 0.6298, Validation Loss: 0.5280, Validation F1: 0.4252\n",
      "Epoch 83900/100000, Train Loss: 0.2477, Train F1: 0.6285, Validation Loss: 0.5282, Validation F1: 0.4261\n",
      "Epoch 84000/100000, Train Loss: 0.2472, Train F1: 0.6323, Validation Loss: 0.5286, Validation F1: 0.4232\n",
      "Epoch 84100/100000, Train Loss: 0.2472, Train F1: 0.6261, Validation Loss: 0.5290, Validation F1: 0.4257\n",
      "Epoch 84200/100000, Train Loss: 0.2463, Train F1: 0.6267, Validation Loss: 0.5292, Validation F1: 0.4251\n",
      "Epoch 84300/100000, Train Loss: 0.2478, Train F1: 0.6302, Validation Loss: 0.5290, Validation F1: 0.4285\n",
      "Epoch 84400/100000, Train Loss: 0.2457, Train F1: 0.6323, Validation Loss: 0.5297, Validation F1: 0.4256\n",
      "Epoch 84500/100000, Train Loss: 0.2447, Train F1: 0.6273, Validation Loss: 0.5306, Validation F1: 0.4252\n",
      "Epoch 84600/100000, Train Loss: 0.2479, Train F1: 0.6314, Validation Loss: 0.5304, Validation F1: 0.4288\n",
      "Epoch 84700/100000, Train Loss: 0.2462, Train F1: 0.6207, Validation Loss: 0.5310, Validation F1: 0.4270\n",
      "Epoch 84800/100000, Train Loss: 0.2459, Train F1: 0.6280, Validation Loss: 0.5316, Validation F1: 0.4270\n",
      "Epoch 84900/100000, Train Loss: 0.2479, Train F1: 0.6313, Validation Loss: 0.5319, Validation F1: 0.4245\n",
      "Epoch 85000/100000, Train Loss: 0.2437, Train F1: 0.6356, Validation Loss: 0.5315, Validation F1: 0.4299\n",
      "Epoch 85100/100000, Train Loss: 0.2464, Train F1: 0.6280, Validation Loss: 0.5323, Validation F1: 0.4263\n",
      "Epoch 85200/100000, Train Loss: 0.2480, Train F1: 0.6286, Validation Loss: 0.5329, Validation F1: 0.4256\n",
      "Epoch 85300/100000, Train Loss: 0.2455, Train F1: 0.6317, Validation Loss: 0.5335, Validation F1: 0.4256\n",
      "Epoch 85400/100000, Train Loss: 0.2460, Train F1: 0.6260, Validation Loss: 0.5331, Validation F1: 0.4273\n",
      "Epoch 85500/100000, Train Loss: 0.2463, Train F1: 0.6221, Validation Loss: 0.5336, Validation F1: 0.4273\n",
      "Epoch 85600/100000, Train Loss: 0.2458, Train F1: 0.6271, Validation Loss: 0.5338, Validation F1: 0.4262\n",
      "Epoch 85700/100000, Train Loss: 0.2463, Train F1: 0.6275, Validation Loss: 0.5349, Validation F1: 0.4256\n",
      "Epoch 85800/100000, Train Loss: 0.2444, Train F1: 0.6281, Validation Loss: 0.5343, Validation F1: 0.4294\n",
      "Epoch 85900/100000, Train Loss: 0.2453, Train F1: 0.6196, Validation Loss: 0.5349, Validation F1: 0.4268\n",
      "Epoch 86000/100000, Train Loss: 0.2447, Train F1: 0.6310, Validation Loss: 0.5350, Validation F1: 0.4282\n",
      "Epoch 86100/100000, Train Loss: 0.2446, Train F1: 0.6344, Validation Loss: 0.5353, Validation F1: 0.4274\n",
      "Epoch 86200/100000, Train Loss: 0.2460, Train F1: 0.6336, Validation Loss: 0.5359, Validation F1: 0.4281\n",
      "Epoch 86300/100000, Train Loss: 0.2449, Train F1: 0.6337, Validation Loss: 0.5362, Validation F1: 0.4276\n",
      "Epoch 86400/100000, Train Loss: 0.2436, Train F1: 0.6295, Validation Loss: 0.5363, Validation F1: 0.4268\n",
      "Epoch 86500/100000, Train Loss: 0.2431, Train F1: 0.6318, Validation Loss: 0.5374, Validation F1: 0.4267\n",
      "Epoch 86600/100000, Train Loss: 0.2438, Train F1: 0.6317, Validation Loss: 0.5378, Validation F1: 0.4292\n",
      "Epoch 86700/100000, Train Loss: 0.2429, Train F1: 0.6351, Validation Loss: 0.5380, Validation F1: 0.4287\n",
      "Epoch 86800/100000, Train Loss: 0.2432, Train F1: 0.6285, Validation Loss: 0.5383, Validation F1: 0.4274\n",
      "Epoch 86900/100000, Train Loss: 0.2443, Train F1: 0.6288, Validation Loss: 0.5389, Validation F1: 0.4305\n",
      "Epoch 87000/100000, Train Loss: 0.2432, Train F1: 0.6297, Validation Loss: 0.5386, Validation F1: 0.4263\n",
      "Epoch 87100/100000, Train Loss: 0.2427, Train F1: 0.6290, Validation Loss: 0.5390, Validation F1: 0.4267\n",
      "Epoch 87200/100000, Train Loss: 0.2443, Train F1: 0.6313, Validation Loss: 0.5394, Validation F1: 0.4255\n",
      "Epoch 87300/100000, Train Loss: 0.2437, Train F1: 0.6308, Validation Loss: 0.5402, Validation F1: 0.4279\n",
      "Epoch 87400/100000, Train Loss: 0.2429, Train F1: 0.6309, Validation Loss: 0.5401, Validation F1: 0.4263\n",
      "Epoch 87500/100000, Train Loss: 0.2427, Train F1: 0.6258, Validation Loss: 0.5408, Validation F1: 0.4274\n",
      "Epoch 87600/100000, Train Loss: 0.2426, Train F1: 0.6280, Validation Loss: 0.5415, Validation F1: 0.4279\n",
      "Epoch 87700/100000, Train Loss: 0.2424, Train F1: 0.6291, Validation Loss: 0.5414, Validation F1: 0.4260\n",
      "Epoch 87800/100000, Train Loss: 0.2431, Train F1: 0.6350, Validation Loss: 0.5418, Validation F1: 0.4274\n",
      "Epoch 87900/100000, Train Loss: 0.2408, Train F1: 0.6329, Validation Loss: 0.5414, Validation F1: 0.4248\n",
      "Epoch 88000/100000, Train Loss: 0.2416, Train F1: 0.6338, Validation Loss: 0.5422, Validation F1: 0.4248\n",
      "Epoch 88100/100000, Train Loss: 0.2422, Train F1: 0.6319, Validation Loss: 0.5427, Validation F1: 0.4248\n",
      "Epoch 88200/100000, Train Loss: 0.2425, Train F1: 0.6374, Validation Loss: 0.5435, Validation F1: 0.4273\n",
      "Epoch 88300/100000, Train Loss: 0.2431, Train F1: 0.6319, Validation Loss: 0.5426, Validation F1: 0.4272\n",
      "Epoch 88400/100000, Train Loss: 0.2415, Train F1: 0.6362, Validation Loss: 0.5435, Validation F1: 0.4242\n",
      "Epoch 88500/100000, Train Loss: 0.2423, Train F1: 0.6345, Validation Loss: 0.5438, Validation F1: 0.4261\n",
      "Epoch 88600/100000, Train Loss: 0.2413, Train F1: 0.6370, Validation Loss: 0.5441, Validation F1: 0.4242\n",
      "Epoch 88700/100000, Train Loss: 0.2415, Train F1: 0.6369, Validation Loss: 0.5445, Validation F1: 0.4260\n",
      "Epoch 88800/100000, Train Loss: 0.2415, Train F1: 0.6326, Validation Loss: 0.5451, Validation F1: 0.4240\n",
      "Epoch 88900/100000, Train Loss: 0.2409, Train F1: 0.6392, Validation Loss: 0.5455, Validation F1: 0.4253\n",
      "Epoch 89000/100000, Train Loss: 0.2410, Train F1: 0.6406, Validation Loss: 0.5456, Validation F1: 0.4257\n",
      "Epoch 89100/100000, Train Loss: 0.2413, Train F1: 0.6337, Validation Loss: 0.5462, Validation F1: 0.4254\n",
      "Epoch 89200/100000, Train Loss: 0.2406, Train F1: 0.6340, Validation Loss: 0.5462, Validation F1: 0.4258\n",
      "Epoch 89300/100000, Train Loss: 0.2391, Train F1: 0.6388, Validation Loss: 0.5472, Validation F1: 0.4240\n",
      "Epoch 89400/100000, Train Loss: 0.2401, Train F1: 0.6327, Validation Loss: 0.5466, Validation F1: 0.4264\n",
      "Epoch 89500/100000, Train Loss: 0.2412, Train F1: 0.6417, Validation Loss: 0.5471, Validation F1: 0.4264\n",
      "Epoch 89600/100000, Train Loss: 0.2417, Train F1: 0.6330, Validation Loss: 0.5479, Validation F1: 0.4251\n",
      "Epoch 89700/100000, Train Loss: 0.2389, Train F1: 0.6374, Validation Loss: 0.5482, Validation F1: 0.4257\n",
      "Epoch 89800/100000, Train Loss: 0.2407, Train F1: 0.6314, Validation Loss: 0.5482, Validation F1: 0.4264\n",
      "Epoch 89900/100000, Train Loss: 0.2389, Train F1: 0.6440, Validation Loss: 0.5493, Validation F1: 0.4235\n",
      "Epoch 90000/100000, Train Loss: 0.2408, Train F1: 0.6369, Validation Loss: 0.5494, Validation F1: 0.4257\n",
      "Epoch 90100/100000, Train Loss: 0.2401, Train F1: 0.6392, Validation Loss: 0.5494, Validation F1: 0.4257\n",
      "Epoch 90200/100000, Train Loss: 0.2400, Train F1: 0.6359, Validation Loss: 0.5502, Validation F1: 0.4240\n",
      "Epoch 90300/100000, Train Loss: 0.2403, Train F1: 0.6419, Validation Loss: 0.5507, Validation F1: 0.4254\n",
      "Epoch 90400/100000, Train Loss: 0.2411, Train F1: 0.6403, Validation Loss: 0.5505, Validation F1: 0.4269\n",
      "Epoch 90500/100000, Train Loss: 0.2395, Train F1: 0.6447, Validation Loss: 0.5519, Validation F1: 0.4208\n",
      "Epoch 90600/100000, Train Loss: 0.2386, Train F1: 0.6442, Validation Loss: 0.5515, Validation F1: 0.4265\n",
      "Epoch 90700/100000, Train Loss: 0.2402, Train F1: 0.6422, Validation Loss: 0.5528, Validation F1: 0.4214\n",
      "Epoch 90800/100000, Train Loss: 0.2403, Train F1: 0.6368, Validation Loss: 0.5519, Validation F1: 0.4256\n",
      "Epoch 90900/100000, Train Loss: 0.2401, Train F1: 0.6377, Validation Loss: 0.5531, Validation F1: 0.4226\n",
      "Epoch 91000/100000, Train Loss: 0.2399, Train F1: 0.6369, Validation Loss: 0.5523, Validation F1: 0.4281\n",
      "Epoch 91100/100000, Train Loss: 0.2382, Train F1: 0.6420, Validation Loss: 0.5533, Validation F1: 0.4233\n",
      "Epoch 91200/100000, Train Loss: 0.2376, Train F1: 0.6461, Validation Loss: 0.5532, Validation F1: 0.4257\n",
      "Epoch 91300/100000, Train Loss: 0.2383, Train F1: 0.6406, Validation Loss: 0.5549, Validation F1: 0.4224\n",
      "Epoch 91400/100000, Train Loss: 0.2390, Train F1: 0.6445, Validation Loss: 0.5540, Validation F1: 0.4220\n",
      "Epoch 91500/100000, Train Loss: 0.2391, Train F1: 0.6471, Validation Loss: 0.5545, Validation F1: 0.4220\n",
      "Epoch 91600/100000, Train Loss: 0.2369, Train F1: 0.6436, Validation Loss: 0.5554, Validation F1: 0.4220\n",
      "Epoch 91700/100000, Train Loss: 0.2383, Train F1: 0.6449, Validation Loss: 0.5549, Validation F1: 0.4215\n",
      "Epoch 91800/100000, Train Loss: 0.2391, Train F1: 0.6370, Validation Loss: 0.5559, Validation F1: 0.4214\n",
      "Epoch 91900/100000, Train Loss: 0.2366, Train F1: 0.6395, Validation Loss: 0.5568, Validation F1: 0.4219\n",
      "Epoch 92000/100000, Train Loss: 0.2382, Train F1: 0.6376, Validation Loss: 0.5567, Validation F1: 0.4214\n",
      "Epoch 92100/100000, Train Loss: 0.2378, Train F1: 0.6417, Validation Loss: 0.5568, Validation F1: 0.4226\n",
      "Epoch 92200/100000, Train Loss: 0.2378, Train F1: 0.6419, Validation Loss: 0.5575, Validation F1: 0.4201\n",
      "Epoch 92300/100000, Train Loss: 0.2374, Train F1: 0.6432, Validation Loss: 0.5574, Validation F1: 0.4189\n",
      "Epoch 92400/100000, Train Loss: 0.2372, Train F1: 0.6388, Validation Loss: 0.5579, Validation F1: 0.4227\n",
      "Epoch 92500/100000, Train Loss: 0.2376, Train F1: 0.6478, Validation Loss: 0.5586, Validation F1: 0.4206\n",
      "Epoch 92600/100000, Train Loss: 0.2384, Train F1: 0.6408, Validation Loss: 0.5585, Validation F1: 0.4173\n",
      "Epoch 92700/100000, Train Loss: 0.2362, Train F1: 0.6464, Validation Loss: 0.5594, Validation F1: 0.4195\n",
      "Epoch 92800/100000, Train Loss: 0.2389, Train F1: 0.6376, Validation Loss: 0.5601, Validation F1: 0.4219\n",
      "Epoch 92900/100000, Train Loss: 0.2380, Train F1: 0.6385, Validation Loss: 0.5604, Validation F1: 0.4200\n",
      "Epoch 93000/100000, Train Loss: 0.2359, Train F1: 0.6452, Validation Loss: 0.5601, Validation F1: 0.4201\n",
      "Epoch 93100/100000, Train Loss: 0.2366, Train F1: 0.6383, Validation Loss: 0.5614, Validation F1: 0.4224\n",
      "Epoch 93200/100000, Train Loss: 0.2375, Train F1: 0.6397, Validation Loss: 0.5609, Validation F1: 0.4189\n",
      "Epoch 93300/100000, Train Loss: 0.2362, Train F1: 0.6462, Validation Loss: 0.5617, Validation F1: 0.4182\n",
      "Epoch 93400/100000, Train Loss: 0.2358, Train F1: 0.6473, Validation Loss: 0.5623, Validation F1: 0.4187\n",
      "Epoch 93500/100000, Train Loss: 0.2362, Train F1: 0.6433, Validation Loss: 0.5620, Validation F1: 0.4167\n",
      "Epoch 93600/100000, Train Loss: 0.2370, Train F1: 0.6500, Validation Loss: 0.5626, Validation F1: 0.4148\n",
      "Epoch 93700/100000, Train Loss: 0.2358, Train F1: 0.6405, Validation Loss: 0.5639, Validation F1: 0.4213\n",
      "Epoch 93800/100000, Train Loss: 0.2354, Train F1: 0.6520, Validation Loss: 0.5636, Validation F1: 0.4142\n",
      "Epoch 93900/100000, Train Loss: 0.2368, Train F1: 0.6375, Validation Loss: 0.5644, Validation F1: 0.4188\n",
      "Epoch 94000/100000, Train Loss: 0.2355, Train F1: 0.6517, Validation Loss: 0.5642, Validation F1: 0.4177\n",
      "Epoch 94100/100000, Train Loss: 0.2357, Train F1: 0.6449, Validation Loss: 0.5648, Validation F1: 0.4164\n",
      "Epoch 94200/100000, Train Loss: 0.2333, Train F1: 0.6459, Validation Loss: 0.5647, Validation F1: 0.4195\n",
      "Epoch 94300/100000, Train Loss: 0.2337, Train F1: 0.6498, Validation Loss: 0.5656, Validation F1: 0.4153\n",
      "Epoch 94400/100000, Train Loss: 0.2364, Train F1: 0.6519, Validation Loss: 0.5661, Validation F1: 0.4183\n",
      "Epoch 94500/100000, Train Loss: 0.2355, Train F1: 0.6493, Validation Loss: 0.5667, Validation F1: 0.4183\n",
      "Epoch 94600/100000, Train Loss: 0.2345, Train F1: 0.6503, Validation Loss: 0.5665, Validation F1: 0.4157\n",
      "Epoch 94700/100000, Train Loss: 0.2359, Train F1: 0.6459, Validation Loss: 0.5670, Validation F1: 0.4130\n",
      "Epoch 94800/100000, Train Loss: 0.2352, Train F1: 0.6558, Validation Loss: 0.5671, Validation F1: 0.4154\n",
      "Epoch 94900/100000, Train Loss: 0.2340, Train F1: 0.6510, Validation Loss: 0.5675, Validation F1: 0.4119\n",
      "Epoch 95000/100000, Train Loss: 0.2365, Train F1: 0.6443, Validation Loss: 0.5679, Validation F1: 0.4119\n",
      "Epoch 95100/100000, Train Loss: 0.2343, Train F1: 0.6454, Validation Loss: 0.5684, Validation F1: 0.4119\n",
      "Epoch 95200/100000, Train Loss: 0.2336, Train F1: 0.6568, Validation Loss: 0.5688, Validation F1: 0.4119\n",
      "Epoch 95300/100000, Train Loss: 0.2347, Train F1: 0.6507, Validation Loss: 0.5695, Validation F1: 0.4170\n",
      "Epoch 95400/100000, Train Loss: 0.2334, Train F1: 0.6490, Validation Loss: 0.5694, Validation F1: 0.4107\n",
      "Epoch 95500/100000, Train Loss: 0.2331, Train F1: 0.6474, Validation Loss: 0.5705, Validation F1: 0.4208\n",
      "Epoch 95600/100000, Train Loss: 0.2329, Train F1: 0.6526, Validation Loss: 0.5708, Validation F1: 0.4183\n",
      "Epoch 95700/100000, Train Loss: 0.2323, Train F1: 0.6525, Validation Loss: 0.5706, Validation F1: 0.4150\n",
      "Epoch 95800/100000, Train Loss: 0.2322, Train F1: 0.6575, Validation Loss: 0.5714, Validation F1: 0.4143\n",
      "Epoch 95900/100000, Train Loss: 0.2339, Train F1: 0.6503, Validation Loss: 0.5718, Validation F1: 0.4117\n",
      "Epoch 96000/100000, Train Loss: 0.2332, Train F1: 0.6536, Validation Loss: 0.5724, Validation F1: 0.4203\n",
      "Epoch 96100/100000, Train Loss: 0.2332, Train F1: 0.6499, Validation Loss: 0.5729, Validation F1: 0.4146\n",
      "Epoch 96200/100000, Train Loss: 0.2319, Train F1: 0.6432, Validation Loss: 0.5730, Validation F1: 0.4157\n",
      "Epoch 96300/100000, Train Loss: 0.2310, Train F1: 0.6580, Validation Loss: 0.5732, Validation F1: 0.4136\n",
      "Epoch 96400/100000, Train Loss: 0.2323, Train F1: 0.6484, Validation Loss: 0.5736, Validation F1: 0.4201\n",
      "Epoch 96500/100000, Train Loss: 0.2332, Train F1: 0.6547, Validation Loss: 0.5740, Validation F1: 0.4126\n",
      "Epoch 96600/100000, Train Loss: 0.2327, Train F1: 0.6561, Validation Loss: 0.5739, Validation F1: 0.4136\n",
      "Epoch 96700/100000, Train Loss: 0.2318, Train F1: 0.6567, Validation Loss: 0.5742, Validation F1: 0.4129\n",
      "Epoch 96800/100000, Train Loss: 0.2339, Train F1: 0.6530, Validation Loss: 0.5754, Validation F1: 0.4151\n",
      "Epoch 96900/100000, Train Loss: 0.2317, Train F1: 0.6531, Validation Loss: 0.5755, Validation F1: 0.4134\n",
      "Epoch 97000/100000, Train Loss: 0.2304, Train F1: 0.6528, Validation Loss: 0.5759, Validation F1: 0.4161\n",
      "Epoch 97100/100000, Train Loss: 0.2322, Train F1: 0.6528, Validation Loss: 0.5762, Validation F1: 0.4140\n",
      "Epoch 97200/100000, Train Loss: 0.2319, Train F1: 0.6550, Validation Loss: 0.5765, Validation F1: 0.4154\n",
      "Epoch 97300/100000, Train Loss: 0.2330, Train F1: 0.6539, Validation Loss: 0.5767, Validation F1: 0.4121\n",
      "Epoch 97400/100000, Train Loss: 0.2336, Train F1: 0.6470, Validation Loss: 0.5772, Validation F1: 0.4121\n",
      "Epoch 97500/100000, Train Loss: 0.2312, Train F1: 0.6562, Validation Loss: 0.5780, Validation F1: 0.4120\n",
      "Epoch 97600/100000, Train Loss: 0.2306, Train F1: 0.6574, Validation Loss: 0.5781, Validation F1: 0.4134\n",
      "Epoch 97700/100000, Train Loss: 0.2309, Train F1: 0.6512, Validation Loss: 0.5783, Validation F1: 0.4127\n",
      "Epoch 97800/100000, Train Loss: 0.2317, Train F1: 0.6493, Validation Loss: 0.5791, Validation F1: 0.4157\n",
      "Epoch 97900/100000, Train Loss: 0.2300, Train F1: 0.6589, Validation Loss: 0.5793, Validation F1: 0.4134\n",
      "Epoch 98000/100000, Train Loss: 0.2323, Train F1: 0.6469, Validation Loss: 0.5805, Validation F1: 0.4206\n",
      "Epoch 98100/100000, Train Loss: 0.2300, Train F1: 0.6575, Validation Loss: 0.5799, Validation F1: 0.4152\n",
      "Epoch 98200/100000, Train Loss: 0.2310, Train F1: 0.6539, Validation Loss: 0.5801, Validation F1: 0.4152\n",
      "Epoch 98300/100000, Train Loss: 0.2313, Train F1: 0.6542, Validation Loss: 0.5808, Validation F1: 0.4147\n",
      "Epoch 98400/100000, Train Loss: 0.2306, Train F1: 0.6595, Validation Loss: 0.5816, Validation F1: 0.4175\n",
      "Epoch 98500/100000, Train Loss: 0.2302, Train F1: 0.6528, Validation Loss: 0.5817, Validation F1: 0.4147\n",
      "Epoch 98600/100000, Train Loss: 0.2309, Train F1: 0.6545, Validation Loss: 0.5824, Validation F1: 0.4139\n",
      "Epoch 98700/100000, Train Loss: 0.2302, Train F1: 0.6524, Validation Loss: 0.5829, Validation F1: 0.4145\n",
      "Epoch 98800/100000, Train Loss: 0.2307, Train F1: 0.6512, Validation Loss: 0.5831, Validation F1: 0.4145\n",
      "Epoch 98900/100000, Train Loss: 0.2304, Train F1: 0.6622, Validation Loss: 0.5841, Validation F1: 0.4150\n",
      "Epoch 99000/100000, Train Loss: 0.2293, Train F1: 0.6613, Validation Loss: 0.5845, Validation F1: 0.4156\n",
      "Epoch 99100/100000, Train Loss: 0.2313, Train F1: 0.6532, Validation Loss: 0.5842, Validation F1: 0.4169\n",
      "Epoch 99200/100000, Train Loss: 0.2295, Train F1: 0.6546, Validation Loss: 0.5850, Validation F1: 0.4158\n",
      "Epoch 99300/100000, Train Loss: 0.2305, Train F1: 0.6552, Validation Loss: 0.5858, Validation F1: 0.4156\n",
      "Epoch 99400/100000, Train Loss: 0.2295, Train F1: 0.6605, Validation Loss: 0.5867, Validation F1: 0.4139\n",
      "Epoch 99500/100000, Train Loss: 0.2306, Train F1: 0.6548, Validation Loss: 0.5867, Validation F1: 0.4156\n",
      "Epoch 99600/100000, Train Loss: 0.2284, Train F1: 0.6625, Validation Loss: 0.5862, Validation F1: 0.4152\n",
      "Epoch 99700/100000, Train Loss: 0.2289, Train F1: 0.6616, Validation Loss: 0.5869, Validation F1: 0.4169\n",
      "Epoch 99800/100000, Train Loss: 0.2289, Train F1: 0.6566, Validation Loss: 0.5871, Validation F1: 0.4152\n",
      "Epoch 99900/100000, Train Loss: 0.2284, Train F1: 0.6621, Validation Loss: 0.5880, Validation F1: 0.4151\n",
      "Epoch 100000/100000, Train Loss: 0.2304, Train F1: 0.6604, Validation Loss: 0.5885, Validation F1: 0.4139\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0000001)\n",
    "criterion = FocalLoss(alpha=1, gamma=2)\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_f1_scores = []\n",
    "val_f1_scores = []\n",
    "\n",
    "best_val_f1 = 0.0\n",
    "\n",
    "num_epochs = 100000\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    y_true_train, y_pred_train = [], []\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        X_batch = X_batch.unsqueeze(1) # Only needed for lstm\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        _, predicted = outputs.max(1)\n",
    "        y_true_train.extend(y_batch.cpu().numpy())\n",
    "        y_pred_train.extend(predicted.cpu().numpy())\n",
    "\n",
    "    train_f1 = f1_score(y_true_train, y_pred_train, average='macro')\n",
    "    train_losses.append(train_loss / len(train_loader))\n",
    "    train_f1_scores.append(train_f1)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    y_true_val, y_pred_val = [], []\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            X_batch = X_batch.unsqueeze(1) # Only needed for lstm\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            _, predicted = outputs.max(1)\n",
    "            y_true_val.extend(y_batch.cpu().numpy())\n",
    "            y_pred_val.extend(predicted.cpu().numpy())\n",
    "\n",
    "    val_f1 = f1_score(y_true_val, y_pred_val, average='macro')\n",
    "    val_losses.append(val_loss / len(test_loader))\n",
    "    val_f1_scores.append(val_f1)\n",
    "\n",
    "    # Save the model if it has a better validation F1 score\n",
    "    if val_f1 > best_val_f1:\n",
    "        torch.save(model.state_dict(), 'best_model_hubert_client_state.pth')\n",
    "        best_val_f1 = val_f1\n",
    "\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, '\n",
    "            f'Train Loss: {train_losses[-1]:.4f}, Train F1: {train_f1:.4f}, '\n",
    "            f'Validation Loss: {val_losses[-1]:.4f}, Validation F1: {val_f1:.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-08T07:48:34.462872Z",
     "iopub.status.busy": "2023-09-08T07:48:34.462471Z",
     "iopub.status.idle": "2023-09-08T07:48:35.327105Z",
     "shell.execute_reply": "2023-09-08T07:48:35.326158Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the training and validation loss\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training & Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_f1_scores, label='Training F1 Score (macro)')\n",
    "plt.plot(val_f1_scores, label='Validation F1 Score (macro)')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.title('Training & Validation F1 Score (macro)')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-08T07:48:35.330098Z",
     "iopub.status.busy": "2023-09-08T07:48:35.329625Z",
     "iopub.status.idle": "2023-09-08T07:48:35.366558Z",
     "shell.execute_reply": "2023-09-08T07:48:35.365722Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Macro score of the model on the test data: 0.4139\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "model.load_state_dict(torch.load('best_model_hubert_client_state.pth'))\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        X_batch = X_batch.unsqueeze(1) # Only needed for lstm\n",
    "        outputs = model(X_batch)\n",
    "        _, predicted = outputs.max(1)\n",
    "        y_pred.extend(predicted.cpu().numpy())\n",
    "        y_true.extend(y_batch.cpu().numpy())\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=le.classes_))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlStuff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
